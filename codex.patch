diff --git a/.gitignore b/.gitignore
index 6cb3a4235b84a5574bc8b20a67d9ca5c9849bd2d..bffd418a695f4ef969dbe44f53343cc984dd3b4a 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,3 +1,5 @@
 data/*
+!data/raw/
+!data/raw/sample_games.csv
 __pycache__/
 .ipynb_checkpoints/
diff --git a/README.md b/README.md
index 0fd1dcc50aaf89f9ed4cc640062f4865720f8b26..b7a53bf3b4cc40ecdca00e08015d8ef48eb26576 100644
--- a/README.md
+++ b/README.md
@@ -1,84 +1,85 @@
-üèÄ Sports Prediction Model
-
-Overview
-
-This project uses machine learning to predict NBA player performance in individual games. It demonstrates skills in data wrangling, feature engineering, model building, and statistical evaluation.
-
-I tested multiple models (Linear Regression, Random Forest Regressor, etc.) and compared them using error metrics and prediction intervals. The goal was to evaluate how well different approaches can capture player-level performance patterns.
-
-‚ú® Key Features
-
-Built an end-to-end ML pipeline: data loading ‚Üí cleaning ‚Üí feature engineering ‚Üí modeling ‚Üí evaluation.
-
-Implemented and compared multiple regression models.
-
-Evaluated performance with metrics such as MAE, RMSE, and prediction intervals.
-
-Produced interpretable results with tables and visualizations.
-
-Designed for reproducibility and modular improvements.
-
-
-
-üìÇ Project Structure
+# üèÄ Sports Prediction Model
+
+This repository contains a miniature yet production-minded workflow for forecasting
+the point totals of professional basketball players. The project is intentionally
+structured to showcase both data science craftsmanship and software engineering
+discipline‚Äîmaking it easier for hiring managers to evaluate the codebase.
+
+## Key Features
+- **Reproducible data pipeline** that loads game logs, engineers rolling
+  statistics, and trains a lightweight random forest implemented from scratch.
+- **Documented project package (`src/`)** with reusable modules for data loading,
+  feature engineering, and model training.
+- **Automated unit tests** covering the most critical utility functions and
+  ensuring the model pipeline runs end-to-end.
+- **Storytelling notebooks** that reference the production code so exploratory
+  analysis and the polished pipeline never drift apart.
+
+## Project Structure
+```
 Sports_Prediction_Model/
-
-‚îú‚îÄ‚îÄ data/                <- Raw or processed data (not tracked in repo)
-
-‚îú‚îÄ‚îÄ notebooks/           <- Jupyter notebooks (exploration, modeling, results)
-
-‚îú‚îÄ‚îÄ src/                 <- Reusable Python scripts (feature engineering, models)
-
-‚îú‚îÄ‚îÄ outputs/             <- Saved figures, result tables, and reports
-
-‚îú‚îÄ‚îÄ README.md            <- Project documentation (this file)
-
-‚îú‚îÄ‚îÄ requirements.txt     <- Python dependencies
-
-‚îî‚îÄ‚îÄ .gitignore           <- Ignore unnecessary files
-
-
-
-
-üöÄ Installation & Setup
-
-Clone this repository:
-
-git clone https://github.com/davislaroque/Sports_Prediction_Model.git
-cd Sports_Prediction_Model
-
-
-Run the notebooks in order:
-
-01_data_exploration.ipynb ‚Äì initial data analysis and cleaning
-
-02_feature_engineering.ipynb ‚Äì feature creation and processing
-
-03_modeling_results.ipynb ‚Äì training models and evaluating results
-
-Example (in Jupyter):
-
-jupyter notebook notebooks/03_modeling_results.ipynb
-
-
-üîÆ Future Work
-
-Incorporate additional features (player fatigue, back-to-back games, etc.)
-
-Expand dataset to multiple seasons
-
-Experiment with deep learning models (e.g., LSTMs for time series)
-
-Deploy as an interactive web app (Flask/Streamlit)
-
-‚öôÔ∏è Tech Stack
-
-Python (pandas, scikit-learn, matplotlib, seaborn)
-
-Jupyter Notebook for analysis & visualization
-
-Git/GitHub for version control
-
-üìú License
-
-This project is licensed under the MIT License ‚Äì see the LICENSE file for details.
+‚îú‚îÄ‚îÄ data/
+‚îÇ   ‚îî‚îÄ‚îÄ raw/                # Example dataset checked in for reproducibility
+‚îú‚îÄ‚îÄ notebooks/              # Executed analysis notebooks
+‚îú‚îÄ‚îÄ outputs/                # Metrics, predictions, and trained model artifacts
+‚îú‚îÄ‚îÄ src/                    # Importable Python package used by code + notebooks
+‚îú‚îÄ‚îÄ tests/                  # Unit tests (run with `python -m unittest`)
+‚îú‚îÄ‚îÄ train.py                # CLI entry point for the training pipeline
+‚îú‚îÄ‚îÄ requirements.txt        # Dependency list (standard library only)
+‚îî‚îÄ‚îÄ README.md
+```
+
+## Getting Started
+1. **Create a virtual environment (optional but recommended):**
+   ```bash
+   python -m venv .venv
+   source .venv/bin/activate
+   ```
+
+2. **Install dependencies** (this project relies on the Python standard library,
+   so the requirements file is intentionally minimal):
+   ```bash
+   pip install -r requirements.txt
+   ```
+
+3. **Run the automated tests** to verify the environment is healthy:
+   ```bash
+   python -m unittest discover -s tests
+   ```
+
+4. **Train the model** on the bundled sample dataset:
+   ```bash
+   python train.py --data data/raw/sample_games.csv --output outputs/
+   ```
+   This command stores the trained model (`model.pkl`), a metrics summary, and
+   prediction CSVs in the `outputs/` directory.
+
+## Data
+A small, curated dataset of mock player game logs ships with the repository so
+you can execute the full workflow without hunting for external files. To use a
+different dataset, provide the CSV path via `--data` when running `train.py`.
+
+Each row must contain at least the following columns:
+- `player`, `team`, `opponent`
+- `date` (ISO formatted)
+- `points`, `rebounds`, `assists`
+- `bet_line`, `odds`
+
+## Notebooks
+The notebooks in the `notebooks/` directory were executed end-to-end and rely on
+the reusable code in `src/`:
+- `01_data_exploration.ipynb` ‚Äì quick EDA on the bundled dataset.
+- `02_modeling_results.ipynb` ‚Äì trains the production pipeline and visualises
+  metrics/predictions saved to `outputs/`.
+
+Because the notebooks call the same functions as `train.py`, they remain synced
+with the production code and are safe to re-run on new data.
+
+## Roadmap
+- Enrich the dataset with historical betting lines to improve the EV modelling.
+- Add a lightweight Streamlit dashboard showcasing the prediction results.
+- Expand automated testing to cover error handling and feature drift checks.
+
+## License
+No license has been selected yet. Add one (for example MIT or Apache 2.0) if you
+plan to make this project publicly available.
diff --git a/data/raw/sample_games.csv b/data/raw/sample_games.csv
new file mode 100644
index 0000000000000000000000000000000000000000..6df4033c17a14ecf5b6e58d38685d6bfb6bf9379
--- /dev/null
+++ b/data/raw/sample_games.csv
@@ -0,0 +1,13 @@
+player,date,team,opponent,home,bet_line,odds,points,rebounds,assists
+Alice,2023-10-01,Sharks,Wolves,1,18.5,-110,22,6,4
+Alice,2023-10-05,Sharks,Bulls,0,18.5,-105,16,7,5
+Bob,2023-10-02,Eagles,Wolves,1,15.5,-120,18,8,3
+Bob,2023-10-06,Eagles,Bulls,0,15.5,+100,12,5,6
+Carlos,2023-10-03,Lions,Wolves,1,20.5,-115,24,9,2
+Carlos,2023-10-07,Lions,Bulls,0,20.5,+110,19,4,7
+Alice,2023-10-09,Sharks,Tigers,1,18.5,-110,20,5,6
+Bob,2023-10-09,Eagles,Tigers,0,15.5,-105,17,10,4
+Carlos,2023-10-10,Lions,Tigers,1,20.5,-120,21,7,5
+Dana,2023-10-04,Tigers,Wolves,0,12.5,-110,14,3,9
+Dana,2023-10-08,Tigers,Bulls,1,12.5,+105,10,4,8
+Dana,2023-10-11,Tigers,Sharks,1,12.5,-115,15,6,7
diff --git a/notebooks/01_data_exploration.ipynb b/notebooks/01_data_exploration.ipynb
index a00b0be99d748549a0f1726430692fb11bba67ff..fe3b1c5671cec1f8272f1370656d6997d160291c 100644
--- a/notebooks/01_data_exploration.ipynb
+++ b/notebooks/01_data_exploration.ipynb
@@ -1,132 +1 @@
-
-{
- "cells": [
-  {
-   "cell_type": "code",
-   "execution_count": 58,
-   "id": "5eb97b08",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "from sklearn.model_selection import train_test_split\n",
-    "from sklearn.ensemble import RandomForestRegressor\n",
-    "from sklearn.linear_model import LinearRegression\n",
-    "from sklearn.metrics import mean_squared_error\n",
-    "from sklearn.preprocessing import StandardScaler\n",
-    "import pandas as pd\n",
-    "import numpy as np\n",
-    "from scipy.stats import norm\n",
-    "import math\n",
-    "\n",
-    "\n",
-    "#Load player data and format into usable features and variables\n",
-    "#Link to kaggle page : https://www.kaggle.com/datasets/eoinamoore/historical-nba-data-and-player-box-scores?select=PlayerStatistics.csv\n",
-    "\n",
-    "def load_and_preprocess_player_data(ppg_file, player_name=None):\n",
-    "\n",
-    "    ppg_data = pd.read_csv(ppg_file)\n",
-    "    #print(\"Columns in loaded DataFrame:\", ppg_data.columns)\n",
-    "    \n",
-    "\n",
-    "    ppg_data['first_last'] = ppg_data['firstName'] + ' ' + ppg_data['lastName']\n",
-    "\n",
-    "    if player_name:\n",
-    "        ppg_data = ppg_data[ppg_data['first_last'] == player_name]\n",
-    "        \n",
-    "\n",
-    "    ppg_data['gameDate'] = pd.to_datetime(ppg_data['gameDate'])\n",
-    "    ppg_data = ppg_data.sort_values(by=['first_last', 'gameDate'])\n",
-    "\n",
-    "    ppg_data['game_month'] = ppg_data['gameDate'].dt.month\n",
-    "    ppg_data['game_dayofweek'] = ppg_data['gameDate'].dt.dayofweek\n",
-    "    ppg_data['days_since_last_game'] = (\n",
-    "        ppg_data.groupby('first_last')['gameDate'].diff().dt.days.fillna(7)\n",
-    "    )\n",
-    "\n",
-    "    ppg_data['rolling_avg_points_3'] = (\n",
-    "        ppg_data.groupby('first_last')['points']\n",
-    "        .rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
-    "    )\n",
-    "    ppg_data['rolling_avg_points_5'] = (\n",
-    "        ppg_data.groupby('first_last')['points']\n",
-    "        .rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
-    "    )\n",
-    "\n",
-    "    ppg_data['mp_pts'] = ppg_data['numMinutes'] * ppg_data['points']\n",
-    "    ppg_data['mp_trb'] = ppg_data['numMinutes'] * ppg_data['reboundsTotal']\n",
-    "\n",
-    "    ppg_data.fillna(ppg_data.mean(numeric_only=True), inplace=True)\n",
-    "\n",
-    "    # Downcast numerics\n",
-    "    for col in ppg_data.select_dtypes(include='number').columns:\n",
-    "        ppg_data[col] = pd.to_numeric(ppg_data[col], downcast='float')\n",
-    "\n",
-    "    # Define the features for the model\n",
-    "    features = [\n",
-    "        'numMinutes', 'blocks', 'steals', 'foulsPersonal', 'turnovers', 'days_since_last_game',\n",
-    "        'assists', 'fieldGoalsAttempted', 'fieldGoalsMade', 'threePointersAttempted', 'threePointersMade',\n",
-    "        'freeThrowsAttempted', 'freeThrowsMade', 'rolling_avg_points_3', 'rolling_avg_points_5',\n",
-    "        'plusMinusPoints', 'reboundsDefensive', 'reboundsOffensive', 'reboundsTotal',\n",
-    "        'mp_pts', 'mp_trb',\n",
-    "        'game_month', 'game_dayofweek', 'playerteamName', 'opponentteamName', 'home'\n",
-    "    ]\n",
-    "\n",
-    "    return ppg_data, features\n",
-    "\n",
-    "\n",
-    "\n",
-    "#Imports the excel file and gets the column of residuals to get the standard error of the estimate\n",
-    "def read_xls(residual_file_path, sheet_name=0, **kwargs):\n",
-    "    try:\n",
-    "        df = pd.read_excel(residual_file_path, sheet_name=sheet_name, engine='xlrd', **kwargs)\n",
-    "        return df\n",
-    "    except FileNotFoundError:\n",
-    "        print(f\"Error: File not found at '{file_path}'\")\n",
-    "        return None\n",
-    "    except Exception as e:\n",
-    "        print(f\"An error occurred: {e}\")\n",
-    "        return None\n",
-    "\n",
-    "\n",
-    "# Load and preprocess opponent stats data\n",
-    " def load_opponent_stats(opponent_file):\n",
-    "     opp_stats = pd.read_csv(opponent_file)\n",
-    "    \n",
-    "     # A lower rating means better offense (less opponent rebounds etc.)\n",
-    "     opp_stats['defensive_allowance_rating'] = opp_stats['team_defensive_allowance'] = 1 / (\n",
-    "                                             0.5 * opp_stats['opp_trb_per_game'] +\n",
-    "                                             0.3 * opp_stats['opp_stl_per_game'] +\n",
-    "                                             0.2 * opp_stats['opp_blk_per_game']\n",
-    "                                             ) * 10\n",
-    "     # Create a separate dataframe for defensive allowance\n",
-    "     team_defensive_allowance = opp_stats[['team', 'defensive_allowance_rating']]\n",
-    "    \n",
-    "     # Clean column values before merging\n",
-    "     team_defensive_allowance['team'] = team_defensive_allowance['team'].str.strip()\n",
-    "\n",
-    "     return team_defensive_allowance"
-   ]
-  }
- ],
- "metadata": {
-  "kernelspec": {
-   "display_name": "Python 3 (ipykernel)",
-   "language": "python",
-   "name": "python3"
-  },
-  "language_info": {
-   "codemirror_mode": {
-    "name": "ipython",
-    "version": 3
-   },
-   "file_extension": ".py",
-   "mimetype": "text/x-python",
-   "name": "python",
-   "nbconvert_exporter": "python",
-   "pygments_lexer": "ipython3",
-   "version": "3.11.4"
-  }
- },
- "nbformat": 4,
- "nbformat_minor": 5
-}
\ No newline at end of file
+{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Notebook 01: Data Exploration\n", "\n", "A quick look at the bundled sample dataset used throughout the project."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "source": ["from src.data.loaders import load_player_game_logs\n", "logs = load_player_game_logs()\n", "len(logs)"], "outputs": [{"output_type": "execute_result", "execution_count": 1, "metadata": {}, "data": {"text/plain": ["12"]}}]}, {"cell_type": "markdown", "metadata": {}, "source": ["## First five rows\n", "The `PlayerGameLog` dataclass keeps the raw values tidy."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "source": ["[(log.player, log.date.isoformat(), log.team, log.points) for log in logs[:5]]"], "outputs": [{"output_type": "execute_result", "execution_count": 2, "metadata": {}, "data": {"text/plain": ["[('Alice', '2023-10-01T00:00:00', 'Sharks', 'Wolves', 22.0), ('Alice', '2023-10-05T00:00:00', 'Sharks', 'Bulls', 16.0), ('Bob', '2023-10-02T00:00:00', 'Eagles', 'Wolves', 18.0), ('Bob', '2023-10-06T00:00:00', 'Eagles', 'Bulls', 12.0), ('Carlos', '2023-10-03T00:00:00', 'Lions', 'Wolves', 24.0)]"]}}]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Rolling feature example\n", "The feature engineering step augments each row with rolling averages."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "source": ["features[3]"], "outputs": [{"output_type": "execute_result", "execution_count": 3, "metadata": {}, "data": {"text/plain": ["{'player': 'Bob', 'date': datetime.datetime(2023, 10, 2, 0, 0), 'team': 'Eagles', 'opponent': 'Wolves', 'home': 1, 'bet_line': 15.5, 'odds': -120, 'points': 18.0, 'rebounds': 8.0, 'assists': 3.0, 'points_rolling': 0.0, 'rebounds_rolling': 0.0, 'assists_rolling': 0.0}"]}}]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}
\ No newline at end of file
diff --git a/notebooks/02_modeling_results.ipynb b/notebooks/02_modeling_results.ipynb
index 221f94adb1c36277debb4f7383e4f719f8939723..29d2fa6258de996f8c0c43d1b12d9baf18a47361 100644
--- a/notebooks/02_modeling_results.ipynb
+++ b/notebooks/02_modeling_results.ipynb
@@ -1,486 +1 @@
-{
- "cells": [
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "143407ad",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "from sklearn.model_selection import train_test_split\n",
-    "from sklearn.ensemble import RandomForestRegressor\n",
-    "from sklearn.linear_model import LinearRegression\n",
-    "from sklearn.metrics import mean_squared_error\n",
-    "from sklearn.preprocessing import StandardScaler\n",
-    "import pandas as pd\n",
-    "import numpy as np\n",
-    "from scipy.stats import norm\n",
-    "import math\n",
-    "\n",
-    "\n",
-    "# Normalization helper\n",
-    "def normalize_features(X):\n",
-    "    scaler = StandardScaler()\n",
-    "    X_scaled = scaler.fit_transform(X)\n",
-    "    return X_scaled, scaler\n",
-    "\n",
-    "# Train/Test Split and Model Training with Random Forest and Linear Regression\n",
-    "def train_models_with_comparison(data, features, target):\n",
-    "    X = data[features]\n",
-    "    y = data[target]\n",
-    "\n",
-    "    # Fill and scale features\n",
-    "    X = X.fillna(X.mean())\n",
-    "    X_scaled, scaler = normalize_features(X)\n",
-    "\n",
-    "    # Split data\n",
-    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
-    "\n",
-    "    # Linear Regression\n",
-    "    lr_model = LinearRegression()\n",
-    "    lr_model.fit(X_train, y_train)\n",
-    "    lr_train_preds = lr_model.predict(X_train)\n",
-    "    lr_residuals = y_train - lr_train_preds\n",
-    "    lr_model.sigma_ = np.std(lr_residuals)\n",
-    "    \n",
-    "    # Random Forest\n",
-    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
-    "    rf_model.fit(X_train, y_train)\n",
-    "\n",
-    "    # Evaluate\n",
-    "    lr_mse = mean_squared_error(y_test, lr_model.predict(X_test))\n",
-    "    rf_mse = mean_squared_error(y_test, rf_model.predict(X_test))\n",
-    "\n",
-    "    \n",
-    "    print(f\"Random Forest RMSE: {math.sqrt(rf_mse):.4f}\")\n",
-    "\n",
-    "    return lr_model, rf_model, scaler, X_train, X_test\n",
-    "\n",
-    "\n",
-    "\n",
-    "# Prediction Interval for Linear Regression\n",
-    "def predict_with_prediction_interval(model, scaler, X_train_scaled, sample_features, alpha=0.05):\n",
-    "    sample_features_scaled = scaler.transform(sample_features)\n",
-    "    predicted_value = model.predict(sample_features_scaled)[0]\n",
-    "    z_score = norm.ppf(1 - alpha / 2)\n",
-    "\n",
-    "    XTX_inv = np.linalg.pinv(X_train_scaled.T @ X_train_scaled)\n",
-    "    x_0 = sample_features_scaled[0].reshape(-1, 1)\n",
-    "    variance = model.sigma_**2 + (x_0.T @ XTX_inv @ x_0)[0, 0]\n",
-    "\n",
-    "    margin_error = z_score * np.sqrt(variance)\n",
-    "    lower_bound = predicted_value - margin_error\n",
-    "    upper_bound = predicted_value + margin_error\n",
-    "\n",
-    "    return predicted_value, lower_bound, upper_bound\n",
-    "\n",
-    "\n",
-    "\n",
-    "# Simple prediction from Random Forest\n",
-    "def predict_rf(rf_model, scaler, sample_features):\n",
-    "    sample_scaled = scaler.transform(sample_features)\n",
-    "    return rf_model.predict(sample_scaled)[0]\n",
-    "\n",
-    "\n",
-    "def calculate_expected_value_from_prediction(\n",
-    "    predicted_points, sigma, sportsbook_line, odds, over=True\n",
-    "):\n",
-    "    # Calculate probability from normal distribution\n",
-    "    if over:\n",
-    "        prob_win = 1 - norm.cdf(sportsbook_line, loc=predicted_points, scale=sigma)\n",
-    "    else:\n",
-    "        prob_win = norm.cdf(sportsbook_line, loc=predicted_points, scale=sigma)\n",
-    "    \n",
-    "    prob_loss = 1 - prob_win\n",
-    "\n",
-    "    # Convert odds to decimal\n",
-    "    if odds > 0:\n",
-    "        payout_ratio = odds / 100\n",
-    "    else:\n",
-    "        payout_ratio = 100 / abs(odds)\n",
-    "\n",
-    "    # Expected value, assuming $100 bet\n",
-    "    ev = (prob_win * payout_ratio * 100) - (prob_loss * 100)\n",
-    "    \n",
-    "    return ev, prob_win\n",
-    "\n",
-    "\n",
-    "\n",
-    "def calculate_betting_edge(blended_mean, std_dev, sportsbook_line, odds, bet_type='over'):\n",
-    "    \"\"\"\n",
-    "    Calculate expected value and model probability for a given bet.\n",
-    "    \"\"\"\n",
-    "    # Convert betting odds to implied probability\n",
-    "    if odds > 0:\n",
-    "        vegas_prob = 100 / (odds + 100)\n",
-    "    else:\n",
-    "        vegas_prob = -odds / (-odds + 100)\n",
-    "\n",
-    "    # Calculate model probability\n",
-    "    if bet_type.lower() == 'over':\n",
-    "        model_prob = 1 - norm.cdf(sportsbook_line, loc=blended_mean, scale=std_dev)\n",
-    "    else:  # Under\n",
-    "        model_prob = norm.cdf(sportsbook_line, loc=blended_mean, scale=std_dev)\n",
-    "\n",
-    "    # Calculate expected value (simple)\n",
-    "    payout_multiplier = odds / 100 if odds > 0 else 100 / abs(odds)\n",
-    "    ev = (model_prob * payout_multiplier) - (1 - model_prob)\n",
-    "\n",
-    "    # Calculate model edge\n",
-    "    edge = model_prob - vegas_prob\n",
-    "\n",
-    "    return ev, model_prob, vegas_prob, edge\n",
-    "\n",
-    "\n",
-    "\n",
-    "\n",
-    "#Functions used to calculate the mean without accounting for fluke / blowout games\n",
-    "def weighted_mean(df, stat_col='points', weight_col='numMinutes'):\n",
-    "    valid = df[(df[weight_col] > 0) & df[stat_col].notna()]\n",
-    "    weighted_sum = (valid[stat_col] * valid[weight_col]).sum()\n",
-    "    total_weight = valid[weight_col].sum()\n",
-    "    return weighted_sum / total_weight if total_weight > 0 else np.nan\n",
-    "\n",
-    "def ewma_stat(df, stat_col='points', span=5):\n",
-    "    sorted_df = df.sort_values('gameDate')\n",
-    "    return sorted_df[stat_col].ewm(span=span, adjust=False).mean().iloc[-1]\n",
-    "\n",
-    "def blended_player_stat(player_data, stat_col='points', span=5, wm_weight=0.6):\n",
-    "    wm = weighted_mean(player_data, stat_col=stat_col, weight_col='numMinutes')\n",
-    "    ewma = ewma_stat(player_data, stat_col=stat_col, span=span)\n",
-    "    \n",
-    "    if pd.isna(wm) and pd.isna(ewma):\n",
-    "        return np.nan\n",
-    "    elif pd.isna(wm):\n",
-    "        return ewma\n",
-    "    elif pd.isna(ewma):\n",
-    "        return wm\n",
-    "    else:\n",
-    "        return wm_weight * wm + (1 - wm_weight) * ewma\n",
-    "    \n",
-    "    \n",
-    "\n",
-    "def adjust_prediction_with_matchup(player_data, opponent_team, player_team, blended_mean, home_game_flag, team_stats, target, print_log):\n",
-    "    \"\"\"Adjusts the blended mean based on matchup stats, pace, and home/away effects, and prints each adjustment.\"\"\"\n",
-    "\n",
-    "    adjustment_log = []  # collect adjustment notes\n",
-    "    \n",
-    "    \n",
-    "     # --- Step 0: Blended Mean ---\n",
-    "    blended_mean = blended_player_stat(player_data, stat_col=target)\n",
-    "    if pd.isna(blended_mean):\n",
-    "        adjustment_log.append(\"Initial blended mean: Failed to calculate (NaN)\")\n",
-    "        print(\"Adjustment Breakdown:\")\n",
-    "        for adj in adjustment_log:\n",
-    "            print(\"  ‚Ä¢\", adj)\n",
-    "        return np.nan\n",
-    "    #adjustment_log.append(f\"Initial blended mean: {blended_mean:.2f} {target}\")\n",
-    "    \n",
-    "    \n",
-    "\n",
-    "    # --- Get player's last 5 games vs opponent ---\n",
-    "    recent_vs_opponent = player_data[player_data['opponentteamName'] == opponent_team].tail(5)\n",
-    "    \n",
-    "\n",
-    "    if not recent_vs_opponent.empty:\n",
-    "        opponent_mean = recent_vs_opponent[target].mean()\n",
-    "        overall_mean = player_data[target].mean()\n",
-    "        opponent_adjustment = (opponent_mean - overall_mean) * 0.5  # weight it moderately\n",
-    "        blended_mean += opponent_adjustment\n",
-    "        adjustment_log.append(f\"Opponent adjustment: {opponent_adjustment:+.2f} {target}\")\n",
-    "    else:\n",
-    "        adjustment_log.append(\"Opponent adjustment: None (no recent data)\")\n",
-    "\n",
-    "    # --- Calculate pace adjustment ---\n",
-    "    try:\n",
-    "        # Find team stats for both teams\n",
-    "        team_row = team_stats[team_stats['teamName'] == player_team].iloc[-1]\n",
-    "        \n",
-    "        opponent_row = team_stats[team_stats['opponentTeamName'] == opponent_team].iloc[-1]\n",
-    "\n",
-    "        # Calculate total possessions for each team\n",
-    "        team_total_possessions = (\n",
-    "            team_row['fieldGoalsAttempted'] +\n",
-    "            0.44 * team_row['freeThrowsAttempted'] -\n",
-    "            team_row['reboundsOffensive'] +\n",
-    "            team_row['turnovers']\n",
-    "        )\n",
-    "        opponent_total_possessions = (\n",
-    "            opponent_row['fieldGoalsAttempted'] +\n",
-    "            0.44 * opponent_row['freeThrowsAttempted'] -\n",
-    "            opponent_row['reboundsOffensive'] +\n",
-    "            opponent_row['turnovers']\n",
-    "        )\n",
-    "\n",
-    "        # Get minutes\n",
-    "        team_total_minutes = team_row['numMinutes']\n",
-    "        opponent_total_minutes = opponent_row['numMinutes']\n",
-    "        \n",
-    "        #different weights for different targets for pace adjustment\n",
-    "        stat_pace_weights = {\n",
-    "            'points': 0.5,\n",
-    "            'reboundsTotal': 0.3,\n",
-    "            'assists': 0.2,\n",
-    "            'steals': 0.1,\n",
-    "            'blocks': 0.1,\n",
-    "            \n",
-    "        }\n",
-    "\n",
-    "\n",
-    "        \n",
-    "\n",
-    "        if pd.notna(team_total_possessions) and pd.notna(opponent_total_possessions) and pd.notna(team_total_minutes) and pd.notna(opponent_total_minutes) and team_total_minutes > 0 and opponent_total_minutes > 0:\n",
-    "            team_pace = (240 / team_total_minutes) * (team_total_possessions)\n",
-    "            \n",
-    "            opponent_pace = (240 / opponent_total_minutes) * (opponent_total_possessions)\n",
-    "\n",
-    "            # Average the two paces\n",
-    "            game_pace = (team_pace + opponent_pace) / 2\n",
-    "            #Average game pace\n",
-    "            league_average_pace = 100\n",
-    "\n",
-    "            #Gets the difference in average pace with that game pace, gets the corresponding weight from \n",
-    "            #the feature and adjusts the target prediction \n",
-    "            pace_diff_percent = (game_pace - league_average_pace) / league_average_pace\n",
-    "            pace_weight = stat_pace_weights.get(target, 0.3)\n",
-    "            pace_adjustment = pace_diff_percent * blended_mean * pace_weight\n",
-    "            blended_mean += pace_adjustment\n",
-    "            \n",
-    "            adjustment_log.append(f\"Pace adjustment: {pace_adjustment:+.2f} {target} (Game Pace {game_pace:.1f}, team_pace = {team_pace}, opponent_pace = {opponent_pace}, League Pace {league_average_pace:.1f})\")\n",
-    "        else:\n",
-    "            adjustment_log.append(f\"Pace adjustment: Skipped because poss = {team_total_possessions}, team_min = {team_total_minutes}, opp_minutes = {opponent_total_minutes}\")\n",
-    "    except Exception as e:\n",
-    "        adjustment_log.append(f\"Pace adjustment: Failed ({e})\")\n",
-    "\n",
-    "    # --- Home/Away adjustment ---\n",
-    "    if home_game_flag == 1:\n",
-    "        home_adjustment = 0.02 * blended_mean  # boost 2% for home\n",
-    "        blended_mean += home_adjustment\n",
-    "        adjustment_log.append(f\"Home game adjustment: {home_adjustment:+.2f} {target}\")\n",
-    "    else:\n",
-    "        away_adjustment = -0.02 * blended_mean  # penalty 2% for away\n",
-    "        blended_mean += away_adjustment\n",
-    "        adjustment_log.append(f\"Away game adjustment: {away_adjustment:+.2f} {target}\")\n",
-    "\n",
-    "    # --- Print all adjustment steps ---\n",
-    "    if print_log:\n",
-    "        print(\"\\nAdjustment Breakdown:\")\n",
-    "        for adj in adjustment_log:\n",
-    "            print(\"  ‚Ä¢\", adj)\n",
-    "\n",
-    "    return blended_mean, adjustment_log\n",
-    "\n",
-    "\n",
-    "# monte carlo based prediction \n",
-    "def monte_carlo_adjustment(player_data, opponent_team, player_team, home_game_flag, team_stats, target, sportsbook_line, bet_type='over', n=1000, noise_std=0.05):\n",
-    "    \"\"\"\n",
-    "    Runs a Monte Carlo simulation by injecting noise into the player's stat distribution and applying the matchup adjustment.\n",
-    "    Returns the empirical probability of hitting the bet line (over/under) and expected value.\n",
-    "    \"\"\"\n",
-    "\n",
-    "    # Precompute the base blended mean\n",
-    "    base_blended_mean = blended_player_stat(player_data, stat_col=target)\n",
-    "\n",
-    "    if pd.isna(base_blended_mean):\n",
-    "        print(\"Cannot run Monte Carlo: blended mean is NaN\")\n",
-    "        return None, None\n",
-    "\n",
-    "    simulated_predictions = []\n",
-    "\n",
-    "    # Generate one noisy sample to print the adjustment log\n",
-    "    noisy_data = player_data.copy()\n",
-    "    noise = np.random.normal(loc=0, scale=noise_std * base_blended_mean, size=len(noisy_data))\n",
-    "    noisy_data[target] = noisy_data[target] + noise\n",
-    "    noisy_data[target] = noisy_data[target].clip(lower=0)\n",
-    "\n",
-    "    # Print adjustment log once\n",
-    "    first_adjusted, adjustment_log = adjust_prediction_with_matchup(\n",
-    "        noisy_data, opponent_team, player_team, base_blended_mean, home_game_flag, team_stats, target, print_log=True\n",
-    "    )\n",
-    "    if not pd.isna(first_adjusted):\n",
-    "        simulated_predictions.append(first_adjusted)\n",
-    "\n",
-    "    # Run rest of the simulations silently\n",
-    "    for _ in range(n - 1):\n",
-    "        noisy_data = player_data.copy()\n",
-    "        noise = np.random.normal(loc=0, scale=noise_std * base_blended_mean, size=len(noisy_data))\n",
-    "        noisy_data[target] = noisy_data[target] + noise\n",
-    "        noisy_data[target] = noisy_data[target].clip(lower=0)\n",
-    "\n",
-    "        adjusted_prediction, _ = adjust_prediction_with_matchup(\n",
-    "            noisy_data, opponent_team, player_team, base_blended_mean, home_game_flag, team_stats, target, print_log=False\n",
-    "        )\n",
-    "\n",
-    "        if not pd.isna(adjusted_prediction):\n",
-    "            simulated_predictions.append(adjusted_prediction)\n",
-    "\n",
-    "    # Calculate Monte Carlo-based probability\n",
-    "    simulated_predictions = np.array(simulated_predictions)\n",
-    "\n",
-    "    if bet_type == 'over':\n",
-    "        prob = np.mean(simulated_predictions > sportsbook_line)\n",
-    "    else:\n",
-    "        prob = np.mean(simulated_predictions < sportsbook_line)\n",
-    "\n",
-    "    # Compute expected value (assuming $100 bet)\n",
-    "    payout_ratio = sportsbook_line / 100 if sportsbook_line > 0 else 100 / abs(sportsbook_line)\n",
-    "    ev = (prob * payout_ratio * 100) - ((1 - prob) * 100)\n",
-    "\n",
-    "    print(f\"Monte Carlo {bet_type.upper()} Prob: {prob:.3f} | Expected Value: ${ev:.2f}\")\n",
-    "    \n",
-    "    \n",
-    "    \n",
-    "def main():\n",
-    "    # --- File paths and player/team setup ---\n",
-    "    ppg_file = '/Users/davislaroque/Desktop/NBA Project/game-by-game-stats/filtered_player_data.csv'\n",
-    "    team_stats_file = '/Users/davislaroque/Desktop/NBA Project/game-by-game-stats/filtered_team_stats.csv'\n",
-    "    residual_file_path = '/Users/davislaroque/Downloads/NBA Project Results Summary.xls'\n",
-    "\n",
-    "    \n",
-    "    target = 'reboundsTotal'\n",
-    "    player_name = \"Anthony Edwards\"\n",
-    "    player_team = \"Timberwolves\"\n",
-    "    opponent_team = \"Thunder\"\n",
-    "    home_game_flag = 0  # 1 for Home, 0 for Away\n",
-    "\n",
-    "    # --- Load and prepare data ---\n",
-    "    player_data, features = load_and_preprocess_player_data(ppg_file, player_name)\n",
-    "    team_stats = pd.read_csv(team_stats_file)\n",
-    "    team_stats = team_stats[pd.to_datetime(team_stats['gameDate']) >= pd.to_datetime(\"2024-10-22\")]\n",
-    "    \n",
-    "    if player_data.empty:\n",
-    "        print(f\"No data found for player: {player_name}\")\n",
-    "        return\n",
-    "    \n",
-    "    #gets the residuals standard error\n",
-    "    df = read_xls(residual_file_path)\n",
-    "    residuals = df.Residuals\n",
-    "    residuals_std = residuals.std()\n",
-    "\n",
-    "    #drop team/categorical columns from model training\n",
-    "    features = [f for f in features if f not in ['playerteamName', 'opponentteamName']]\n",
-    "\n",
-    "    \n",
-    "    # Remove target column from features to prevent leakage\n",
-    "    if target == 'reboundsTotal':\n",
-    "        features = [f for f in features if f not in ['reboundsTotal', 'mp_trb']]\n",
-    "    elif target == 'points':\n",
-    "        features = [f for f in features if f not in ['points', 'mp_pts']]\n",
-    "        \n",
-    "\n",
-    "    # --- Train models ---\n",
-    "    lr_model, rf_model, scaler, X_train_scaled, X_test_scaled = train_models_with_comparison(\n",
-    "        player_data, features, target\n",
-    "    )\n",
-    "\n",
-    "    # --- Prepare latest sample for prediction ---\n",
-    "    player_row = player_data.iloc[[-1]]  # most recent game\n",
-    "    numMinutes = player_row[\"numMinutes\"].values[0]\n",
-    "    fieldGoalsAttempted = player_row[\"fieldGoalsAttempted\"].values[0]\n",
-    "    sample_features = player_row[features].values\n",
-    "\n",
-    "    alpha = 0.05  # Confidence level for prediction interval\n",
-    "\n",
-    "    # --- Linear Regression prediction with interval ---\n",
-    "    lr_pred, lower, upper = predict_with_prediction_interval(\n",
-    "        lr_model, scaler, X_train_scaled, sample_features\n",
-    "    )\n",
-    "\n",
-    "    # --- Random Forest prediction ---\n",
-    "    sample_df = pd.DataFrame(sample_features, columns=features)\n",
-    "    tree_preds = [tree.predict(scaler.transform(sample_df))[0] for tree in rf_model.estimators_]\n",
-    "    rf_pred = np.mean(tree_preds)\n",
-    "    rf_std = np.std(tree_preds)\n",
-    "\n",
-    "    # --- Blended Mean (weighted average of LR and RF) ---\n",
-    "    blended_mean = (0.6 * rf_pred) + (0.4 * lr_pred)\n",
-    "\n",
-    "    # --- Estimate Standard Deviation (blended) ---\n",
-    "    historical_std = player_data[target].tail(20).std()\n",
-    "    blended_std = (0.6 * historical_std) + (0.4 * rf_std)\n",
-    "    blended_std = max(blended_std, 0.1 * rf_pred)\n",
-    "\n",
-    "    # --- Adjust blended_mean with matchup, pace, home/away ---\n",
-    "    adjusted_blended_mean, _ = adjust_prediction_with_matchup(\n",
-    "        player_data=player_data,\n",
-    "        opponent_team=opponent_team,\n",
-    "        player_team=player_team,\n",
-    "        blended_mean=blended_mean,\n",
-    "        home_game_flag=home_game_flag,\n",
-    "        team_stats=team_stats,\n",
-    "        target = target,\n",
-    "        print_log = False\n",
-    "    )\n",
-    "\n",
-    "    \n",
-    "\n",
-    "\n",
-    "    # --- Sportsbook Info (manual input) ---\n",
-    "    sportsbook_line =8.5\n",
-    "    odds = +100\n",
-    "    bet_type = 'over'\n",
-    "\n",
-    "    \n",
-    "    \n",
-    "    model_prob, ev = monte_carlo_adjustment(\n",
-    "    player_data=player_data,\n",
-    "    opponent_team=opponent_team,\n",
-    "    player_team=player_team,\n",
-    "    home_game_flag=home_game_flag,\n",
-    "    team_stats=team_stats,\n",
-    "    target=target,\n",
-    "    sportsbook_line=sportsbook_line,\n",
-    "    bet_type=bet_type,\n",
-    "    n=1000,\n",
-    "    noise_std = residuals_std\n",
-    "    )\n",
-    "    \n",
-    "    # --- Calculate EV, model prob, vegas prob, edge ---\n",
-    "    ev, model_prob, vegas_prob, edge = calculate_betting_edge(\n",
-    "        adjusted_blended_mean, blended_std, sportsbook_line, odds, bet_type\n",
-    "    )\n",
-    "\n",
-    "    # --- Output ---\n",
-    "\n",
-    "    print(f\"\\n--- {player_name} ---\")\n",
-    "    print(f\"Averaging {numMinutes:.1f} minutes with {fieldGoalsAttempted:.1f} FGA/game\\n\")\n",
-    "    print(f\"Model predicted mean: {adjusted_blended_mean:.2f} {target} (adjusted)\")\n",
-    "    print(f\"Model standard deviation: {blended_std:.2f}\\n\")\n",
-    "    #print(f\"Random Forest raw prediction: {rf_pred:.2f} {target}\\n\")\n",
-    "    #print(f\"Linear Regression raw prediction: {lr_pred:.2f} {target}\")\n",
-    "    print(f\"95% Prediction Interval for Linear Regression: ({lower:.2f}, {upper:.2f})\\n\")\n",
-    "\n",
-    "    print(f\"Vegas {bet_type} line: {sportsbook_line} at odds {odds}\")\n",
-    "    print(f\"Vegas implied probability: {vegas_prob * 100:.2f}%\")\n",
-    "    print(f\"Model probability of winning bet: {model_prob * 100:.2f}%\")\n",
-    "    print(f\"Edge over Vegas: {edge * 100:.2f}%\")\n",
-    "    print(f\"Expected Value (EV): ${ev:.2f}\\n\")\n",
-    "\n",
-    "\n",
-    "if __name__ == \"__main__\":\n",
-    "    main()"
-   ]
-  }
- ],
- "metadata": {
-  "kernelspec": {
-   "display_name": "Python 3 (ipykernel)",
-   "language": "python",
-   "name": "python3"
-  },
-  "language_info": {
-   "codemirror_mode": {
-    "name": "ipython",
-    "version": 3
-   },
-   "file_extension": ".py",
-   "mimetype": "text/x-python",
-   "name": "python",
-   "nbconvert_exporter": "python",
-   "pygments_lexer": "ipython3",
-   "version": "3.11.4"
-  }
- },
- "nbformat": 4,
- "nbformat_minor": 5
-}
+{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Notebook 02: Modeling Results\n", "\n", "This notebook trains the production pipeline and inspects the resulting metrics."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "source": ["from src.data.loaders import load_player_game_logs\n", "from src.models.pipeline import run_training_pipeline\n", "\n", "logs = load_player_game_logs()\n", "artifacts = run_training_pipeline(logs, random_state=0)\n", "artifacts.metrics"], "outputs": [{"output_type": "execute_result", "execution_count": 1, "metadata": {}, "data": {"text/plain": ["{'rmse': 5.062, 'mae': 4.386}"]}}]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Prediction samples\n", "Player-level predictions along with the estimated expected value."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "source": ["artifacts.predictions[:3]"], "outputs": [{"output_type": "execute_result", "execution_count": 2, "metadata": {}, "data": {"text/plain": ["[{'player': 'Bob', 'team': 'Eagles', 'opponent': 'Bulls', 'bet_line': 15.5, 'odds': 100.0, 'actual_points': 12.0, 'predicted_points': 18.27, 'prob_over': 0.941, 'expected_value': 0.883}, {'player': 'Alice', 'team': 'Sharks', 'opponent': 'Wolves', 'bet_line': 18.5, 'odds': -110.0, 'actual_points': 22.0, 'predicted_points': 17.42, 'prob_over': 0.253, 'expected_value': -0.516}, {'player': 'Dana', 'team': 'Tigers', 'opponent': 'Sharks', 'bet_line': 12.5, 'odds': -115.0, 'actual_points': 15.0, 'predicted_points': 14.8, 'prob_over': 0.909, 'expected_value': 0.7}]"]}}]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Highest expected value bets\n", "Sorting by expected value highlights potential opportunities."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "source": ["sorted(artifacts.predictions, key=lambda row: row[\"expected_value\"], reverse=True)[:3]"], "outputs": [{"output_type": "execute_result", "execution_count": 3, "metadata": {}, "data": {"text/plain": ["[{'player': 'Bob', 'team': 'Eagles', 'opponent': 'Bulls', 'bet_line': 15.5, 'odds': 100.0, 'actual_points': 12.0, 'predicted_points': 18.27, 'prob_over': 0.941, 'expected_value': 0.883}, {'player': 'Dana', 'team': 'Tigers', 'opponent': 'Sharks', 'bet_line': 12.5, 'odds': -115.0, 'actual_points': 15.0, 'predicted_points': 14.8, 'prob_over': 0.909, 'expected_value': 0.7}, {'player': 'Alice', 'team': 'Sharks', 'opponent': 'Wolves', 'bet_line': 18.5, 'odds': -110.0, 'actual_points': 22.0, 'predicted_points': 17.42, 'prob_over': 0.253, 'expected_value': -0.516}]"]}}]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}
\ No newline at end of file
diff --git a/outputs/metrics.json b/outputs/metrics.json
new file mode 100644
index 0000000000000000000000000000000000000000..3d505e77cf346eddfe8c23d0f449d1f8ad7d37cd
--- /dev/null
+++ b/outputs/metrics.json
@@ -0,0 +1,4 @@
+{
+  "rmse": 5.247,
+  "mae": 4.881
+}
\ No newline at end of file
diff --git a/outputs/model.pkl b/outputs/model.pkl
new file mode 100644
index 0000000000000000000000000000000000000000..9db2f63b0e6c5045fca171fbb6ef3fca8757d450
GIT binary patch
literal 9650
zcmb7JJ8v6D5LV&9jw8PU2QiEkMiK+IVT<>o;*v!W!EoomP!$N0b@CAqNrOkF3&8ZO
zl1q{NfdFxzv?^01rK<dy+&rkAot;~fgbMmRJ2&&qH{a|o=U0CD{oxjV7I*6Do1M|*
zxIC?QPA1c`o;8b4ULB5)C!=rhpRdZd?bCWPZGLVZ|JeM{JX&mz4_dq7=x{cf*3HYm
z7u!=@a8S<<XJzy9$>M|Av@Gl9yXH}~wYc$h`DR!TC*yBtXQOw{&DE3gaCSB=o5js{
zli_$)A515wr^E5vX7S;yYF}DSPLG?t!48Ld{j@xp9ejUydRDeilL000(RBE>a*qpo
ze0Ee_r)aAii>rrqJ*;PSQ{CDd+$L|;?Y%+DU+?S<@)uwJ)c$$Pt{s)LgEpQL*FARY
zp8f%!_f@;D_y<1!dh2da%cIHJ_}JwG@4fHVXY?{ypVL#hzPbzM^n44#e9kLd^Aw|e
z;hBF5<~_D)&3i7o-8nuE&1Evqdl7nHTw5lCAl!4WNzU;*Bw@V<lMv>`lS|B=krOYf
zFCd9)&ihmT+Ir8RFfSf@<~PBdc>xe5&U>+;cS0-l&Xoc0+33&z+CNCOZ+MT?D>KY>
zz0wo>Ae#(xL`DGl>@|MSoK||V-*1s2FI$>C7RRqtlM(V;u1RzJU}=qr;1z>y`VZAc
z7Wil`*q^!tEcR=75-JdaZ{&;M%bs><=0<6sD|nVw2A+lNuP_+VEKFSpCLbUI9{5<R
z2M!tGotxM*4_G|MrC8ble)Y^T)w}o{OUrEs=2lBZXlcoaMrPSvK>ASRD$O(5uoR*f
zy9QF28xk6mzyw-x^q2I$xWxj0IY5A+A3LOSDlH(zY02fWx1|@zR?l1`CB}%MpjAxT
z!dznJ#TrVOk`1J4X_by$bl0v?Hr>0d#o*oQT}=umJ(#BkhjcK46d8$xhdZ{*BUja@
z<PyAFx}$}JBS2&fWr&oiApQ4((ao4S-LWXPuNmpK0G2u8E+jUaW7=J*Mq(!^&%M|+
z?kie7CM1-G=N(g}Dxpkeu1r>{S{cNA%MHEP$Rx~%4n_vvoq1tUO!Ga#!9NDvExtpl
zoM|v@jb7Ek2)-M$86{TES+VWReud9(9`3rTiNoD$Z45?i8xu$1-7aJVBNMXeVx%5z
z=^Syw<|D+s*flbOk)5K~XP2-+BbQxe(pBY2-({|W6lLlgN}y8}l4>ciPE~lfHY^cy
z-cm<_6y7tVSA*Ey^sxA@&3jye4h2SYA=tgmI3rrSF!-*Kk$bZzAn@-!WP;df26QoU
zLrK*XOPs!2K%%66#;k1#oL?X`5DZt$i#?KRW~8bKyzFu)6TQguzOQGK>n2OE5t#=r
zcIFktzSbt!9WJb?9l_l?2<lWN--&JURLKTnw^G%(OYdEbT!P(JRkTO{90Bu!(LkoO
z8|(s72O~6+52&7Z;5!wG4uayekj%qig8dBHKrq(fLgOy>!0V7eDuFTNb*ch)tDDe#
zxkYMmPn?Qb!JxS;6O|HD?HrWi3@FC1wYiEAI5!xHxZk5f!C{(5#=5vab7kUr=#d~2
zOh#Lq&|Cx~B-Pq2#k?CQ8(mf5or~uM6PUYHEprU!a{(lcY5<bS8TBqGmKm|{t8QXm
zf%n3gtAW0gN`pDS$O|UuCMQeQ*;|jY757uYY;wU^-K4#z7Z?quO7MEI12Xcgz3js_
z)lNwj%_oNZSBCc(#i+}JV8}~w`^A@9o_SCvm#S4JG-vnFtAYf)>GQl}?4p}iXr$)5
z(0AS*c-{lfxVhTLg1z?4bujXn)iui27d;(}sA_SJh=sw3UKRH<R<8!J&(S3?(ju@9
zM&Q1oisi<3AIl^NEWGz=OX;Pmg(DZS4=@eSJi_<f*y(A`2o=i>6~or<a|A7cS6t^r
z_-^gRFqmcg!x$zwpiJB;UaEkMCmc?&E#c6zB(4>#ePj>}^+Z=Nn5yX2!X5lKR07_`
zMN<`gw^G#v7FD$_7&Qr2w6^x%bK4(lgQC4lSz3edLL)ox^tg#ZQUx+rYhy5?`NR%8
zKi{aE_|)Q+Nw)`gT$j%1xw@o&hb(FDT*@x*k><0Ii3x|XK|%8eh#1~nC9e6bUJY<x
zqnpUNz8B+zaezBp(~Tj=)dFdag9sywIWG0QM}V|Qpi>np);9)a40l6;b?o9W!Gh++
zj^4#R0nabsOlkxZN!0>UD}lI1v$hagfqPCPEd|!*e7gm)Tjm-WaXRRfC7}c>4nokY
zl44Spj4~mR0{6^quB>seuSQwwCZDD6+I-hFpJg7YDp$<o44R8kwmZPY0e6;5&s>*@
ze_!j8C0!;tn+Rafd#pW--&-{@;-+>(WUSwtVn7-iiTb`xN#Sg|K-KFaa1gt@h3Jf3
zQp}lK6pO`9D?Qxxu*scwYkI`I6ZJjsF%ooL=PajVJLG%r=U8jlXhyF1?I1!iOJ{<q
i?V8U*Mgu9%+LpOShAWTVL^IO^GJ^Z1V3%h{JO2Y<liWT4

literal 0
HcmV?d00001

diff --git a/outputs/predictions.csv b/outputs/predictions.csv
new file mode 100644
index 0000000000000000000000000000000000000000..7abe606eb98f2b51b744d40964d5f2fbfce69149
--- /dev/null
+++ b/outputs/predictions.csv
@@ -0,0 +1,5 @@
+player,team,opponent,bet_line,odds,actual_points,predicted_points,prob_over,expected_value
+Bob,Eagles,Bulls,15.5,100.0,12.0,18.41,0.948,0.897
+Alice,Sharks,Wolves,18.5,-110.0,22.0,19.01,0.625,0.193
+Alice,Sharks,Bulls,18.5,-105.0,16.0,18.96,0.613,0.198
+Dana,Tigers,Bulls,12.5,105.0,10.0,17.16,0.991,1.031
diff --git a/outputs/results_summary.xls b/outputs/results_summary.xls
deleted file mode 100644
index 8b49f4a3db1e0eec5b439e13fab6926acf0570a6..0000000000000000000000000000000000000000
GIT binary patch
literal 0
HcmV?d00001

literal 43008
zcmeHw33wDmw{}g|Nl3^_SOTH5CnOBn!)ihjWD5`ig2*~aCdojOfmwhkNDvVhPy_^2
z+(mIm5JY7Of(xIhtnw+S;EI5v2p=M1?t7|wX1XVf<iG#_JpX-eCQo;!YO2oi);Xt6
zRrmB9_%!I`Q?GY9#av!DFn9KMgAemk)NAm**j^4~_`IQkiuV7b@g7xeum3>^_-HYZ
zUY_ihQ6GEnW^T+&%h)OW-{?Ul#=gNZiOppGj1}l-8!b|yzSuO&W|00Lzw)>YdJV}?
z55pUPcN(@1wLz>imn@i{L-_eM-flZT4`9K}&;4chKW3ch-y6Ld`rYi7%iAsE=O}(|
zkF$oo$@_f4Yf@PP`xWiAY&n@aSo>)PLU$`OF$<H}NTz3I{F&Gs_Ww^?4dmTUFttWr
zG;c|_F6@K~2T$N&W=7~=C2Q{B`VW*^gJ=&{3EX?j=xdn23jG4`w_r4?AVn>gB3YwB
z>+93qqZMsWz%H(rF4;>^E9@n-6>a;sqU{aW-B!bLt`oCgfkVc1w`FL1y?&!%KCPhZ
zd);*1SjX#b%OJx)%Nya*m3e|Hi;9VgPL7UFnVQ&dQi8oODKWw$5_4o%)#nq74P}$n
zjiQ)0>*j2vOHtE7nMlRMm7`o+xlogvX0skFjj^dDN)O2{nOvNdz$+#t_LD23dPYI+
zsR_AL!9~Xs@rSO;emx{*ryi23M-EG7ebvl_25Np>GzH6?94FH(mIR-5GPU=2@U?g5
zterhivQT&!W0x8v{$HHxrM7xP;{QGl8q9N!mz$vPg9?uS8}cU}k8=DQ*T2?G{fo`i
zH%I4{X4*GL=jCSFHz&{Q&9rZhPHW|9j(&6Uyw!|68=I+rxS9I<czvfv<MmK8^;?>$
z7xFZwv!R*xLY~I$1)YFK@(4Ub?DeaHg4VQK(~fzp=JY!_>dVV_b>G#UdA!N%eGo&q
z9sYp^{AIV##AfP~o2l>7WIdw1sJ|$am;I}~z20H}!VcTn>yNM^#_D|S{^+N!2P{HP
z<j{it5puG+#`P|IgY4}c_z3$6wbvhE)9|*7ojx*oLEj<gOEPY9{kou_uy$d<`4L_p
zY;O<x0%w804`#-uaE5|S;^S$rKZ4YZJ><Y4%wF%J7q#bc25SxelH&|x?M1zZx}Mgc
zO}7thvb}dR?TKB}bbK4pnWqh9^X&3*aR#vo4LOVEYkRW!s(Sj+4eO&&teA;DV>Fp#
z8tl;?nS)#74%DPo9Yk{93JxSlt2hwgt?EES*s2aRhOO#AgV?GLG$^g=K+{*NI*|Rh
zssjaxR&}7r(W(v<Qd-r4Vp*#?Q1EV5hZ|bkA*Zz+avdGWGw^Eo2ag+wHZAIq;NsJH
z=z#SneA<;mV|UK~C*rOFqoB1Nl3Lp#xwRd7wzh+=wH>g0Xn6=+QR=7aKoLzj$eQ`u
zfi7c))deE3JxaQEaMQ{GnnIme2}x38B3M%WGm(azmWiZa50SKVH4#_+GeE>?vyIeg
zEP9HAE4Nv_i&uEa#{B;IPa2xnKS4!g9rIGVmYqn$2Q3lFRudWDj3f<b*C`}<&}BF?
zLB!kPf;l;}n~`My!ww?evWg29ENGDA7Y#e%p{(;!)Zruk@@=ASzSdQ!K4_~HDyM0o
zE?l_KNT{5goJK+^>+C{Noh%cx3#F`UEELxA3Zed--wfPM38h5kzlW5oH)cU7;f;iT
zBcbff8tOC-q#A41!=V}3KfRPOz|C%r>({S$5V6~U5?VVmW!?3|?dq5VAck;E(hOsz
zwt>c4^hPsbG^9nN1ktWVL&N??T5Q_1sgcnr>+D)k9cc5H-Ds3`jc2W1XzSF1>_7$W
zeC<sx{@5QKJRIS*krsqIsizETguA`Y?vIV*Rup<U<2DM72iZ=f`M5<(A19GU(h<h)
z%uueBuCXMvUin8N`wLqpf~~-RCgK|WUA-q-MFfSWF`+EHc}!^e_>bxs%3CHvYvO+-
zvcIrpBG~!-XCi6oEfa}R5kaA8OlYCeJSMc{{YP~S<t-Dz!u_9#>@RGYNW}FJNlR~;
zNUVwo3Qc1|YpLcjp>3G!z@%j&ov(+;{=$}tbiW=VY3VH!iBl0lp=nHLx!61=w8e5A
zn6yj;8#Dh*WPf4HM5OB>l9t{wk$4pm6q?3_R>aL?LfdlJfl13m!mo$O{=$}tL|zY(
zv~(qrm2SZ-5Yrb+ONo_wN&`zv4K>!(71|MO1wkjjG#(KR{<yA^!eW`kdg2(!O7Ul4
zHMj~aRu~%Q$GklZ<@G;YYVf4@G}|Bxh^5^gViV-bCap1>s213WH3(<pX(+$?&C#aW
z1iP|HZ_FmH1vX-p!r6Ek%6I?zVbg3vT-jtaX49huHnfg$N7e(Nybb05`uS?pY(ibx
zWHx4_Yk>_d7i2bCL-~bI&Nt1bgDab?#%$7BU?b96u8ohO{EG_*nr0J5Y%*H5wC-S&
zaUGVnzi`q1vrV(<=*p%EON(xSjndNg7heA0<)+zma%IzmrNy_vMrmo#=9~MQX4Bb~
zO%s-u)B+o&rR^_Vb>fev*>rJb(}bn<YJrW?()JgA_xP7hvk7-)(}bm^x4=eeY5NPe
z{P1+sY`PMgtd=cJ0-LPsu(Y)Fg3YIzX4B1;O%s+D(*hf%rKP3+_QIm3*+jUqX~NPH
zT41BJw6yfWhbJ`6rn@VfCM+$v1vW}cOH0>(^n256Bv&>~SXxR8Y?PLkmj3VRkDF!_
z>B^=FOUr11jndN6((nJ=(i9s%+?as8%Q0^bbeT81HF!5WS2EUN+8u%@O_X@abEO}P
zb`pg}xe|?ZA*!?@#(tWW)-=%=CsEjsE74dNqDq@#tn-YRrisQniNac3i6*)bRayvR
z0guabxU2ecPNJ|4SE4;#h$`)Yu_u#OHZ5tqlPD~~m1wF9QRV0}Hu8C0Q$)46GY*UJ
zJbl>;Z6Ec>Yr-4cSspI@l{sc$Pudj04k2Yn^q#g6<q;3WohP^|lCQ5SwN>e@MpMlS
z?Lsv{x3GqGEFT1`ka*en?Os;g`ei~2M*Ao<_YzUs&ayM0?Iq5@3s(^7L)y>Kps})~
zRh4{HrIl_0xSs~sck(L@r8A^_LsiuZ?E)9MIyU%1u1X|>rECUL!+gA}!k<zq+KS>y
zp>m|{QqlgCmqRL1vP&gOcBw>ZC3d)y>f9SvXeG5Mp6+0h4@j!<rw1#>sBLnc7uqJc
zwDrPWyw0`~n~0fUvZGJWIuG=TbLr#JphX`WzuS>=-%{LhXXm1;^F|MyOAqe`zeYXO
zygIO6$iUg4xihQuHF~SbTq}(=%(br24px(L%WMc_gV<d8R=*l3NH<`bA%eul0`s{j
z)8>_Z^l7kV^YVdi*q#||GQm*$sp)FEG<dMVpk#6}RoW4^(*iR)t@g<Gv4R+4(3cr&
zDkQ8GTm*Fw1hPXQ5ZS&FC{;i}u}0t~0EcOxFi?;qQ}l*pA`q^0YmY^Sf;eKIEAgNv
zh>Q5w4Dp7XvYkIb5h9+hB#s#9N<6p;;vx<<LtLZ=Zk%|Ak~m_aOF(cBX@WS#Los6B
zN?2C9`Law5BpX^Y(*{$psfWxh6#5JWvNK_eH0VzEZ@|94ebDIQz<<;I1CbyhE)^PU
zW*Ew3{~zumOee&pLO#$lFz98f2;lCpMn^2NM<3ea_5yHzEF1E(kp`R9tVeip3Cx<V
z2+Sivm^3xRrYNw86%CK4xL9J>cO9;%$OaFSs$+1+bhWG+29_ha*HC~UQZo7)ymc;C
zeQ=*ENQ^XD4J))IY8r07@E4+Cg-{Io*&{D)RNF%uZ8AFptti<;nkd;rnkcPwYsdO9
zY-)|NS^0?1abem4q(^ZK8jra$<Wq!HjX6~~B@rdNB%)-OM3g9C_O0^-b}?!ZJUuZG
zMbO#oSojlUWUBqhRL2^vRX{6M-OD`y!!s7vVFlWRS7U3}5Q+Yrgvm-4;IjAN-kFmi
zz{QYxaHCS~FA(nbI3l#Qm&n9|*Z|CqY`orFLm^9q*BrH=ZtW1M$Ag0zer1nZO@&pO
z#5uzEYj0-vD>g}%L%SgSjRlbsuI(6zT+82$fbJ9wZJ3zSfTEGj<`(2^K^|0rS(LU@
zve-0!`~6~QHK>?S_F`iy4F+rKBic^v5d}|Sw&Lo^Gx*BFGm6is-%^;d27kLXS{#gJ
zo@vkiVtYf@<NZDO97bNCw;Eu0MOFG*gBh`Rj8$)y#@5cH%08K~QvOi9DK=PaRaSgD
zSYK`6pJK$xJuHY0dA72$T4{*UP*sN8C=yarb!q9z68>eTC4vuaZW8sLLu-P;&RA9x
zZ<Q(xR;k)pV*>?Hy+vPIDGe$!)MAtpvUQmm$x^m1D~o!M598s-AXOSGDwCy3gER*_
zRFbK@oH*;NrGaIJ5`C?SdiK#}WhP5~blI7S*oz*E4pzxnV>Os(>#LF_(`<toRIF$@
z%vfDrE9Kc>v1Y{GQN3=$HLF4iXpBN5sCH9LnZb-(JPK?zrTQAF*i>Syv6yPGUpQWG
zkpNI{X{HIJEmEbvs(g;VR<c%_O}2_k{5MGH<}y$nTbze;(bzFK4;(X=1kBWBq$W$5
zy39U_9H|stHdF;tDd~wod0?s4rmvDU0ff*bJCQ&)8^E%}V8xoYpcZmS1^ODmZQ(@H
zb-jCoNCr?(ETV}SGL=ag8FqXneNCAFEwg88x=tD@BO=WqRiqN5RjSgPD-7mj$zrND
zSS!g#tR|_-WSRk0A<l@}DuYEDYctmv%qZrWN=j;_B9qx_w2-h_x=aY0rOV1rM6tL`
zN|lhy)MAL})84wY>}098E<HQ3jA@GD2;{|8JZ-6f6HwYAp-et!z`JsIAZ2h8T*LsE
z(Bs<;$tcZ4y>OyZIEhGnCEkkyu^Fw2t^{f(lr5mvS+b%`Ns<jAtCGK`G*!vXf=?yP
zr4o8n@|IPgVDDQAnj{5L(IdH~oR4@~;l!FERM8fw8C@m3BR0y;)o5tpp9v-u|3sM-
zDdFvFxbh|_Hxp$u2;0Dd7#MkL09atKRGTn@dHNay;hCxH10&DUrDP_C!dq=KVbxZZ
zsl#H1>7@}Sv%bbk7Lt~xOT`f2Uq+wAK`?Y0ZG~eL-zbe3Ge{aBrQl}s6tpZXmS&m_
zWyVrkh@c)l)6=Cny%fzdVTvR4RmK@oo<VP^GSs3xOkZWFk@Czoaus5n4$H_&meR9z
z85v|6umvjjq2euY5VH|U1uV^~pF#dzO^%g@Hr!%|a{J7bEQV63Z$UelBx02`rxILd
z8!BMErIq@c3Zen0t1{LYh*(-5T_%7@0U0aJCkjR3--F634DiR1y#`WRV*}p;Q%$L{
z6uv%8Uk1V>N@d@ILcls5aHOW`veLQ3LZK`;EEG!5N;Jc{jWsp;(kg?LD<!3-^huV=
ztBmF4Qf|-Gw3K9Ns8p@5Eip)zN|UXsOtM)Z9|WCg?_`&_R9^KNBm<=5%5&c<H<_g*
z34?E_l`syRHdH_|W`J-G-lNLOELfu5$XQbXtBE3gtrcC0%tk9PGK;v}8@NLo;FFbz
zNIc$vAXil-<?GD|k<u`;j#N%a*JVQI3|&Tg;uJD+@=IFjkav+M&@|SRhmaqaadR){
zrYzx1zGFt8RIERA$Y{xrOJL&Um(EZ7@XsWCdyIUYt}mp*zj~uq!U~$A0eQdpev?Qr
z(=bI!h!G?kQ6tBq{^ELs1a7@R0qTsg8fKEY<lD^VT5ggExfrK(%u%T#2B$+)9zHX(
z6LD!c4_<?X4Z_>4Mnkn_hH)9w6hH)fNT5JPfq+7S2qxt`4v0`g0fXMnlwqR?Az-6V
zgplOt7EZwl8PU>%2ZcZ4P>w$WOYoo-9w|q0gJ{!#EB>gy8UTpkMuE@9GY@<EQVB{F
zNbQmec#JX~3a!<gB5|f5EcBtEOga#i>7XdWt|&Wcr9uZQJ0NCE$x^MiR2s^Xr4pM}
zvKVVh;m`0?xTwV>Rhq0+nqjOd(@SO>%oj@u8jyGkpOi5rmBU#umm?7H$!Cs<e*mYi
zgzd}z15biUTMRSxW(osVgTC4#&+0V8*=Wj^Xtov&;WoSt7fDH{)MPdrcqB=%5B4Z2
zPDmu(MDuNt9`X+?o32C58li^=*=F)0%wq^<NNKiC8c1_KHGz>0)SDsLNW^KQwXy@s
zs7CmObHM@aVU$nRX}V0r?o^}!nTh1WdJBAC8e`PY&{y*YDY`xgkeH=YG7@WqkE4Z%
z2_m+b;NX(p3?U5IDX<u;jhMW7%s@s{&6!$kGiPFQwn#>+P8tmGVb0|UL6Q|IN{LL3
z#s*24mGCaD(pS$klvP7Le3KRFl@at6Gk`sZlJKdVMOk>fMLve8Z2_W0Mvs(%M!E{L
zC=ypwShv_f%fdC3%8X@F4Vr*;wXL)g2n@4T8EqD+7z0>kAOzA7evl%iW$3c{Bt|1%
z3t=!LH7f+j6x)o_5af`?YMWV)azYxCPeCT5kL9|kNJwc&0q6mHvnD&kG#MAio<l#!
z0Db0QpaE)XT9d#-dn2W4W05sN)ggMb*(g%AOkHox3#mwnQpnDRnJks`u@xC|LTW~G
zYF6S{rWpjkqxoNWdm$^9eNmm}P;Q|NqU7sTV^5?gdI*132W)#HBf<MA=@GF)#3+#h
z*?r&X>lr+PNNg6O0WFY(B!@BQ7|j+dvJd#g(AgMf146B1daKl<ipH5TSDIlsepXD`
z0#2GB=U{5bC&qGl=A2{1gd}El@_nP+33-9Oic)wpX8&3z3)my#3-W_<Bj#>cyJJ#R
zWCnI3ut-eONG_~W4bPV-Rt=RbR^nMg88$dpW87|p(@Nv?HRGzV<l;t|!QC<~o80n7
z%)n}E<R)D<-Da_(A5GezBb8K{=9s{sf)-2=(n$VTQ%-TGOn3??7nt?6Jh?-LZ>XUR
zDNC1%2$8Mpotbzqwtvc9HR2)Bt`QLfH<M5Y>4s1X{7TJ+IreZ26Eu}eX8u`?X^x1g
z6hV~G@o-H*kTO^#;gEejAt^O2ld`vA`f3EL5eVFRK9y!*4#mPFBSV*+mbkGIDirv^
z6Udh8DfI!(3R=fhVXcI~Kxkk@^rfXH8`g8gu1XJM;&{=>5Qus^s?`Qq4VrLssy0FR
zD#L6;m7xrCht<B2kr5}x2B`vi%(PXZNs~*o3~MEgERvxtqyv=Trpk+#H2dNOcUtF}
ztd&k{a|8k&e;roWWDKBn@d%RzYL39BE5{3=tq=0AG^FlXiDQ5lLMgO_-6>qg(u}ik
zCYU3u03jCJ+_wM;PZ)Vf<`D{e1w{rkvTt}xtwa`yhz2g)qIom3fo|}?honpisVAlt
zDk{W4p9;v$T^5=QnhjnfOqe^kCJ11?DY~ZWQssqgCeNxUu%*%pgEpFlyJKRcp%s&J
zx!F`Lm^xTFF{PLa$4Jv<OT}1@=%mNQ{KxZaOBI<f#8!rqB$ss$0zvi6DudO4cBHIM
zDl}TL#7C4t1SYpDA&-PA#DJV4P1i@vkd-zweNcvY01lLA(8N|^fH(7`y%vcDw<RJ#
zdAn^UrP)|JAQLGtj-!mH=2jC;J=ngW<#>uNBaN?lQu(GthAurbaRy`K_^b^_f~R2#
zV>JS4K8Qknr)WafRGoAa(kZORVbbOLQgRCzj3dkeTBjY#So3kl9s`y%`IVS?tVU>z
zOvhG3;$cq#29G5TMhZ?Xa+kp-bD3DO;RD*DK#GDr3M@7VsTJ~oI^}c>Ux|T)bBqr6
zOs7D~SZ~iY^i|a+m?gYS?4LmBYB|M%GJ0Wl7Gp(?P8vgVhaS{TbCO}lb9&kn4T=%C
z<$Nq9hves&^)ZW3yyKym63_|^dyTCETrJ$64Q4sn#K4M}jwB3uKP@-2X<(Xjb?#||
zzJ&rgO<~Ehp$H$8l~;Ho8doDhgqbv9e1s>4q0m-ggCE|C)u)+uSQ1kCCQgPfH7yah
z408W*!j0@2_Cj5eG+-;vScYvPO9NYh@5TR^f=5<hCodaUSSI2BGx+}@?d+v7M*C;C
z;s2BPpN;Dnld#M6Auc)m?9SLxTs8d@1N;OobneBD*AaX>;R^Pk67h|ckziv*_<I=3
z${O6@yb>W`5x&2)0g{i(#b+?B=saYLNQgc28S4?u*qQ>ywudlQstv;d0pu69@A%7&
zt=7Klw_5Q@|1ft}G~C@I6uX;L9m#(BDqt73S6Nrc2~uogKKWOTbt-K~S|;n}R#(0J
z;723(qy!GSJmjxM-}fB0Zd0x{_NO~Oxc`Hv=hc7sa7@^~e{XvJrmL3=4~@;+Aca*W
zf1ZB%@qXW$cXapOvS;nO=ZC#^AulQBZ1~{G>%Yz(_4zB~?pfHSQ-A&XfVCIj-nl&?
zdr95UdmbrXf7=f;D+)IaxPQ61`|@WG{n^{?qs-ZHb=T_Je{36lqSM)X9_;<?zWig~
zyKmjt?dAc$e1Bza%s0#5csnO+<jceIwTm{_uQ+mU!<8HNh2`n~^;Y~P-LpyeJoWK}
zcgJ4oyz%rDL*~KE4PQwY+AR&<v(fLKsh?IzoqPVUtKZ}IoIC#6gsSad-oNSod0A8T
zkKEl5I_*-<>5#+w7ff6LL>h2GS&i5F&z}FW9yn!Td@)39D%LfYUOGD8`M{^s_oVnO
zIlp+vqJ#5CAKKF?c6P7z%kz6ZGoPJGSWp=iemwl_@lhXm`M#sQ^V##4Ul{QBtM^?w
zwdzMH?2#9}_I#6{^HJrg*#mYhxMSbqXP=MNPMkaQu4isLzGdq6qJz)$|2Q>#{gACG
z4+RI@{rRZv#joa-9o!dqXxO0R86`0bo_}!G)MMS(KHm9cR^j1GVa3O?r@i{XhJ6j2
z_oVE9eAMm*uO)v!$fG8ERiW{_lBYKG`gY8Y<r@qy9*H=xW!sg{u0fT?iq5EA9kvJx
zA|;|{N-%OULoda71TLLo2a_zsZ~qA2JyKxqsrgUMS^jx;={pI7N;ZA;>O22o`Rlq2
z{NTw$PaHq?{kMy<KlwWJ=%d5^CnT@)_P^KgvF`3Sf1Q{7eE5bhhID-|x$4vh9e(&}
zZl`^3EDQO1=!cfk^P`V0U;N6JFQw16Bpr=BpZw*Nw_>IbxNq?I(}yo7elzH7Qk<__
z@1})+sjtVWzR2*eN{o>=D8v>jq>|X@CJZ-)X9w==czVIj=XSgvbNtp$54wM};@g<p
zcNZ6bH)QCl)nRkqk`j-<-C^GgYur2!J-x<l$EBiB{{zhb)}J0oUH;^V1qDmKn?7jR
z*uQe?o?HC$eXIX0|6^8p@AOA@+;+bIbGs9NxMSn95n<;;-(~RwK8xSCG2(__&dnR=
z?;bh&(BM_E+agA8)Sj=t{m*@q--wLv`Yrn|<n@JT^f89FU*8mU>&B&fyRH7lV`q3u
zM6}NX^R^xO@wDH?_pR&4CafA?Qm`UrNRi+40B`q0dj<}E!7uyye@zUH2uVDW_rQg%
z#ml<+Ec^L^dwnD0N*=v%GW6iB+N&2opWyw(M=4JZ8S=-|5n&gnZrfBl$FsUDZ>;XY
zE#J+)I5lpK&&9#9JL0>~{(VHdSBh<~tUY^-_2@Y3l^6f~^pcUCxpeZ`yY72s^R_9v
zvBNum=JxOd5npZ@HtXnn6aO6Fv3JKA-`{Bb_~2^;Z*2I&ZRf@@Gcu2L+wRr*uRq;x
zf2nBtk#SU*SF73e*%vRax~2V;MNz|69E^H<(hK80>fCpUU#BlGy*uN3^HYcRpG*%e
z$d8yj{XWg`?>60h-$9>m`>~?jdt-*W^%?pbyCmKFX7Rp)12IwSD}%ifhpnyqKJSH_
z?>sOuY1M@V)wAAM_+acSb2TBaZ+!L-kEcHv+T-l0`~zKXS)Tpc)T#Y%v;B7N&HH}*
zwAbU;g3mpuk6G4Za81Y9{E5GO`M}hMYu7sNp1SMrUw?To`}XY{e={xk`@+xX7i=Fj
zVA7U{6Tg~w^}^3DtugJqdgjw7rp$fAH0#KgQ{93~gSwvFd~)r3Gjpqb*W~<i;p|Xr
zR6$pt(1kS*oLRlJ>&e|7qr1PlaB|2Er<NP$)nENKWXX(v-;@sR-!JFh67OxFcB)SK
zC9^(y%NoO}PkML$GyBKV@HtBlykI(Cy{dQnnq^~#ytemwbH8`ne;j>p@I80+-knzT
z_3J_JKYn;X?B3VU-tg0`xPRw*jT(9&ckhf9?SJaKFeBuP*wjA^-$ZL)on5uLA*M3r
zOg~%56K@aM7IycoAI?d!?VsCyS?s;@d-O|qZtL#L%a_iJIUe%W=2<->cOT9#oN(Yw
zY2>`LC0#$6(dSyw9eaPUUA^J4y}A{{(=PmUB7f=UAI61O4^9|4|KC|dqr$J|E|m&K
z&)oZLz|K!kgg^cG?tp{|XMTzI==aOc{z3ik@~9Z|i09pZmhT_1bNd4ihwS><r<-){
zqqK?rXKy+i7XQ`h%B4$2R-V@v9_)Okv}^y{PwEd$d!h9A&Oa>)Dtl=1xpprv`Ec1y
zm)1?wRIfNQBW%of5kVtA-1^({o~JhFJUqOA$f~_}_c}a}O?k8Wt25?pOCx-jypg?W
zp|{5uId^w_ZFGCj(;M%&?S;>t(e~Lgd_cPe+edEucGpWMQn#&%Z@(<*#PH?2kF8#~
zx8|em$FjN=Jmz1nIXp1t-@mV)7&z-hPRMB6P4_L^VRpZK=#vv{*@K7A?~Qru<tu%1
z*KOXs;Q7nH?frJiPq+Sc?_=9-AKzXvVan%^oi(pM_4lG3BSMy~jQ0D!EOpkGTeIGL
zWyBx5Ox3Hu{Qme|<r9w2I)32J1C=MTGCrUC{ho}B%@JN-glCqdJQFeCk9*d9GT-aY
zLtEDsZI8crdT{-xkNn*}xksM?zwf=$HD%e!XL?vRE?g9De%9dj$#*{%-1xJ0eM<Kp
zcMaQDRQBSMs38y6z5d{o|C|{&x9|OzCw#rM-=%pkOzZJdu6gT}o0sffIbq4@hcZr^
zV<(RN>tbPtKc;WZA29u~;G#{(BK6fjtho8o@(qO@dqqAKSJC~hK_BmV`o$xoCU2SM
z`{e4|Ja3=l{p*Y!5wE_Mn3odYalq+=SN}EY{i9>fPp`Or$f#cF&xL4GZpnyWxO?6&
zKRxoz+ZX4avBn*F^`vphowM)tNm_H~)}=MS7I^HsYxC)`FO7d{*5s+j%5}EWiDOP*
zlXg~Q^f-F?^=&V_Hn8S~>;rp03C-~N<mCNpP99o3Fkt<qnaoo9N2lil`{!NzPo7oV
zYwE2l9t~fx^2iEv<fB6h-v6fW*-j063rZr2f{*3f{yq_qad7C~<uC0%dhO<Y4;@*2
z_1_;ZJT|%4x4YTpXMdhEW6*>z`sdx7z3<(tuY~RDbMw$msoUP^cIneQblrY0^@!X$
zC9%i(|J+k|%zMzcXKq+{SzjCX=zCvJGW=`Pu4{S2K3G0saK^HtamDAVYEHiW<agGK
zV`|*bCiYA3bR=!)IG=a&Z_-yk)A##~*CyY!=g_9x-detC-9wobgANZ(da>%y!)rJ1
zd87UQ&o7kU^i@e_W@=34J9{5JG2jWyjKgKw#}d9XxcNPP{CxSAub<93zW=G`I`#TN
z|IizoZ+dfXVZdCUEiaArN&0!s^V5Gkx4NUx`Pm!iK65C*{QKy3!xtG#U+DSD)OE+t
zZ=G=2W5wW*FHWRpn%*(Gjq1^3(5-v7nBI9gXWtFQ`ru{1y)}JUhZS)j%ne-rckO`W
zD}4w5{{EJ=Huo;C>>c~tzdUz*`FPUWQx9!;YvWrReSYn~VgGvTVvEm?^ow7;wK1aS
zpOqi|o@hAwlKYfLi`I@=WK18v`}sjh@2*`JeY*Pi+nYbKytcLBhaAkMjZ+2xgUg@T
zici9kNZ@j<YPJ>m5ubk*34@$3jqrUpCG^hAcg)e6Oo!hNd@%0IyAQl_#Qo0iGX1l1
zVn(0)+5gpKt!{~a=flQ#);zW^q%`fT)XEpTX#4*3(5y#xS8qFae{ONu$a_BTSGIB5
z9rv5Ef9_E6;P8YIaWTaSy41Di_VL43t~+q=*ei9f_I~Dpao<Hf^W4A>-#IYkvTgp8
zzdfp%_g>77lEB-Jvd*iE9%<Not#_AuDtdJfoBa3aftJq~dnP>n{{EBEkG@#w@vn(*
zzrFWshw2))p7;)5a|tw>DPB#a(?!G81Y9#pXYUl?smL!~JGy3Q&W@dtx;9FA6!5!J
za!r?<ls;>U5>K97X}B7JlSToSG)ie&Fo~k!o>&jj9X_6HGPKX36q`MYyDT16tYYv1
zTZ+1+iaKfsK1@7BGEnsp$#!n^H97H0z`v>33A#Fmv9IeGE?Ci{7yWQ9V*&hq5Y7y@
z2Wr`0FZ_0BL`hN3R9@eM*C+Aw9lWNFub~9pSlq+ISgvLvKG}`+74EOYv52?6lb_?z
zx}3j$$f2jJ+21EPsGQD8RJ?x*w>i6mBHc@(!CfP?c1!24!#Vc<0lU`WhRJm<I0%Wv
zxj)vR;&l_G07AGWk6wg>Sn+Ayu&ct~SCQi27{I8GP!3^#sOqQ?A|99LXorO@>Q<@R
z5f-j>SnxKgqrnaVCH%t;HG(hF_C|H2pldrUm>boR1-P~&6LPJi)w^pQ7TS&K2rJii
zSco^OBLrRBVWHlr4vY3ib+qbs?MwFKT1WQeT1RUe*E;%|tZN<FziS<RP13cFz9#5e
zM_-e3t)m5@YaM;F*0qklS?XHX-KFjt_glv3VJ(b_k_II*3Q=-HiOfrs+)*0sD0!en
z7AQXR#Erir93?N5MmkE~D2;NIwCG2(nds+(Qm&)qi_$<xsU1o*9-^fmN~D1(`J+U(
zE=uiDA}bfA0PySWC<UTa=O_iCbho1vjDF+^x8tTf(mIFb-uy!@Q6bL{pj$OLO$|^8
zU^E`0r8`QRy${MQJy0S)5&b+-!hW4x@=}$&<&vPHMF~4WG8G?HOJ7x~9ZF<zqMsk{
z7by4hM~N&{aBq(i`JyNVpyZS#P%e4l{(BAX-3ws1hQ2!Z)UDm>(E(jTSOEfZedk=<
z1fXH={Edeo6pY5?&LjXCgcB$?4ivdHwRGb^kui&w9H{ywTvRs<SODFpAh%Qkg=Y@S
z!U-x$pxgj10TnM(Q36GQ)v2NzWDKC^bjsWXP&&CE0Y#xpa8Lq8gR7+C1S%Z*5Kxai
zOs{UaS^^GtXyT5=AhzA38$OO_K|w4o1a}3qs~j@Cx!}ak4NoE_>Ov-R7$<ggXKw)9
zRLJDcu_Fg3?A&Pz!uv2Ty*tN_9G#@68;zavx~s5rhtZ191Qmf@7nzC@J9ia!?keou
zF)@?Oo#cLm9ff4UU5Ooyuu>K!cJ3TIbi?apj+U^rV<!j^G!&UhRPyE=Hcj?Fx|1`2
zzAC_3dT?mStlTk+dH{d`c@~f60(x+GDDD$ox@FcWl7|W&4;4HfvT50=DB<x?!Q;W<
zvHPHh3{Qg0T?vl|fO7gEnY>aKB|IJ+o=TpMxWTjlml7TiZaH>%D7-o0p&PLS7)>su
zFurq)l07_ma(FZzB0PC=XlObREtSxCs-W>yLE|YyBf^s>JjbbqrwSTR6*P2zI$4gy
zq49*jJH5_R1r14}q^X3)lS3mdK0A6_gm=9bI;f!W<j~MON|r+rd?0&Lwj3{&<#?$q
z$E%U$c!6{tlR$ys@lsiimkJ*G(vA>U@Dz?EEXPX)kCzG_FBLpqGCXk{9xo1$-LdGt
zZl~o?Ky<?61z!*)FATI7hv&e4dR>HL0WPKGcyV|lWq4>3%W=R%-<}9Sf-4mER#}d>
zu$+qzapAnV<wQGLDlNxb1&y}~8gJQhl4L4M%kfr0<E?_mTLle0EXQd%^gRkEG&B%S
zXuMU>cq^Pr3(EmiN@%<}G%+$XG;8Oudf9R)xCh`%{{k8cR{``~O>Sf4otX2Vypt<M
z1{uIt++;O`zf&AysVph2Mk_-j!m(CmHCh!kS`{=}8JbX;J3(Wg^XdBy0en><WKlw+
zRY9ZW(5&TC*_B;d44MiWEr%vaR+wf=Cp11Bnm8F69|trPj(s>ZVulo6@5A9qbhK8&
zL%$~BgvUo^IX*HxBIeK&NR=&>Grf-r9v@ZA@ljb0ec{6i4^dRoR63OphbLDo^Z*aw
zQd*7=ho^@O59L@n?4)ctlrIM09!6m~lm<C1ho)=iR7$f`0B-uUw^Twy@y98guL>Hn
zGNK~V0bdm~zADS{RYBvcvK(I(G`=cm2wo+3B{aSq8nDOfS3m=(l+gHcXmt3HLL=pg
zPH5V3XnLWJ%(I;;-n0`=RreG(Ydn$`0^ka-+)@cmI~6qTRM4~&(9~tgRFqcJP6bUn
z6*TQ+Xp-fA%6QXG1r24DPH5VxoT?p%hDYN4Qaw4b3YvBtnp7DYN|P~(PY`PiKMqZr
ztT63_h)JBB%8x@Mb}EEB_;GkL9j%q{_^IH*Q#NFAX*m33%jwD0^ix@mp9&s74v#&3
z_LJceIgX!drt(w4LleFe9zPX4ejFZ=<M`%MR8zs@$KlDA;i0vG6CQsK5AC9m<<NGK
zGsp24mUHA~u9QEA2G{!KmP%;+RnYjWpz)V2XMjvaX*vEXX#7={<1a&VgWQiS$3BVs
ztDvDzoY45Ipz-I>h;SSZ%K=nMr}F2}WXaGF`5aa!TMj)UIe?zV&lRR0F>zW>dk)P2
z-(%0ryf%;vNEvegz7=L~t%Rq&3Lbo~Ocr+slFRloJU8Sb^5jmWGn-QHEAv#YNy%R6
z(^Q$C(v{jf03o}kU|hgX?rgs<{pr0qG_dVeptR?p@O9~*X#fQvDM4w^L7@!`GHqh%
z1O?MGYWks$$kLXg2*SiRfP*rNqaxfXfP;ejJ>=F(Py$q-&^CY=Ljr}C`ouRZ7w6oG
z^>n@^SAarmWamOXKn6uj+O+a@<}+k3VpbB;5h$OQAN_H9(q|kLTKWi{l<oy^Q1)I*
znDoHA{s09a*+C%~XqAMiTDA?^KMX)lD-;XlFxZy{fx>N;uH)kr$RWsgv{XV6sDdES
z0fFErAc&Qz*xg2a#)l>MmU<e5KouZ?G9Y%zlz;@P03qcI*sA|{O<h}flmil|0wj<F
z!dC}_$Vvc^9T35m7M3?cF%pTEg-&>aI6MWi(zNC5be$j$j|jSAdnJfNG|16f2~m&=
zq96xEWF<kel|<*lJ|ulTS;^FTVI@Hv6nmHrl0k{$VA5lwoUtTG1q$s$6tKH59zV9w
za)^TxqymM$j%nYi2+5_?&jAX-KnqDs%d(XOa~KB8iqX#~IfHAku#&6|T%=$Q!4OAF
zB?Q4L2!d4*1Pci2`sG6Tx?AdTuAd}B5UjEb{8SUT+oK0P(#q*5!72!7SPR&`?{l90
zdgo3K0X@*m=_vHvEqPb#&m`CdAW_;yFpnO?!HNK(eHSMnAsmolvYPaZQcgfZ1R(Wd
zT@=Cr8R}@M1SCWSNQerM5ZNXYbD^v>tsZBGO@ycb36TNm%LjlSzU8!u5C<Sa2LeRH
z+RH7KV1#fm5)m^lB_zNe0FDxj5Do@5t2h|6&x&2yTSR6O%E2g-RiuaKI>DfaXd=}5
zJ;qsvaxjX~at9us5z1FW8kUud7WK7sW_dW{PCGi+O{!Na9ja0~R8~4&rmIvs)S)zm
z%TPv2Z^-<(-^ha^I)tjMAe1YfOEchrFR(fW5K6^Ex#Hs>6d_2<D5v5bxZ-0_M{%Ts
zO7RXt@uJmSzz$sTv1qvi^g76jr$S9leQ7Q>8X#x~KK|#hhq3tV!5oSU9b~7-AUH7k
zbe<+VMF&+}=pe%pBXd*2(Ln`A2M$Nlf7X1ta>+sN6dhD>bl`A61jrEtrvN-kI681R
zZj#}k9j+WE$#xLN;TSK&5vGD8Ou%vDvs}P14#&+Ljvm;nCa1uTIuz8@m*wJIHw^Dt
zT{_;gI<ELhyW(LgI|!2%&z9*b6%SJ>9>&NHqVBiN3im(46%SJ>9>x_H2^MW40SKky
zVO;SEvf>nvor-tlir*qD-chA^N1^!EC%J$fx#AOL#XHK1XF^#G8^zCqNM)8p=lTh#
zafZQ;D#bgh6sO0!IlaE4O7V{Pq=0?6_MO$s1HRyjcT_3fkt<%$^MxyL005y>ydzh9
z5`-cLpiM+<Ny{VNi7P%Cb>sk@REl@visR{tT=7m^@hNCYp5I9*URMAGHFeW+={yi;
z#(L4YZZhhf*<&Y_;+<s0#X^i8H0O-}l!ZDIB}%^v*cp$EpsfDyam72S6sL)o_|Pj5
zBMu;xig)6Q>+vBePTPl0#XEDwr=pG&r(YLzhP=*V#Q$2w74OUypN5vCcxQRUd)L#5
z-^|bbaHi`ObQW>`7TL!;s}%1nE8at<s~qvpD#bf9QanVz=Wvo?A6LAyO7YHI@j7zx
z#mBKg2M|idJ9EWLAPy-`ds<j#$s^u{D_)8^QoM^w@h(E~<&Sa!yKu$J(2{~%7p^$Z
zs0Vz5;1+`#FNmpOv!FQQem$wrN1yT0cg+4>R3LPbK@f{DdN7~U?7OHy=z>oQ*bC2&
z%ni|R<{)%YfzXA6K*4tOwzym^hDHTK7Y>2}LJ<g*5<5W%=OC1$jzFNRKF-k(7a-)`
z#X$(?AXK0w#r<%3^rc*=oI9aj#QktZ+~3XPemD~;b0pfalV$Y;jeRK<&f&1<gW)n9
zVkeCrAn1f6Tm=WM3kukmF<uKF%72H$5w3zGoWntDhD!<O5Cs5_(k8+=9F-7+;GoM+
zSW3w@(UrqtL><A=RRu>^0mnEI_q%d9rlTb}1N}@MjXj?Rb4A=AnhRyIIYVbY|2yoU
ztI7_#%8I9OnCX#*&M44TrFd6-Qo#DW@!{;9PrS_)@2XO~D_49u)SeU&gD3zXl!|xd
ziqDW0r)z4scpxj@jVo^70;bD*PCMu(6hE<s3)qb-UL`BuO;$XO)MO`j5ePZ;^u8z6
zxP-rMD#g3Wii_|^4_S07-i<3>4Lam<-S9~PyX%(2+rJH+&lT^cQoI{iyoh_iMMMDr
zp;WvZSG)$qXvFD~P>w_K2(GvZbu{7;D#as&;&m&y;t^c&nX*U`Tyc@&kg3O@uZRN0
zP#iy@Sx+Evv#;Z!&@uWEDi9)M5bXSwAVjD@h~OZ6wQ|YgTMqB%AVjD@h~Oa5b?wks
z<1zXGMF~O#2VoY3A`s|?0w)OFISBSp*j)uecLBmiv2@1IkwFZ5DD2KbP=><p>QD$M
zSX~M~PpKzB?7rV!1wwZj1hI`m52$qdes>iJ-SLS%19*{x&|L*WcMgKc04~820E!ZX
z?i>U&1UUvWcj9tLm7A|7QPW=&uIVlx;+;5m(0HTXTN9-5*IZ!%IK-c)M!fgb(0xl1
z=(*l=LKmT2>*(T>YaLx?a;<|{jq1oXUE9%R3D>%KmpU4333XWT$*wN(!M31|EM8I#
zwj>67>EqnuB|g|zw4@j($*$f5!>Osek<Kh1XI4j1kI56heX%b&23T;Rm9G7c40<%E
zvP7AV-PI+$FJN=q#U$Lmba#%Bo)&i+$(&1DLJ}WfHz^=j!hNAy7_w@BB|gA&AP#kn
z#DAyakz8^68Yj}BI7OI9t~kGz^SKDbkz9EjD3J1zvhuWk(VQfQ#;?QTy`0!f+{GQM
z+DNXveP)Z4tvi8(N)Ie`T6d(%x+C#P0V|wvSMSf>+rgEO<kqb@Ig=|N$(0wI${}!Z
zfT6VRNUr>BS$VQHr}9x;`MId0@t_}pb_RI5>kkU85@}u(SG*Q2379CZI8CLK9yr9~
zT$FI}Co6IZguXa47E5Ol=W^|<n<$3`&`?ClAavy*L~#)4Qk#%QX#r7?rGQnx_xGmT
zE_}#cJWA!_QHnU%2_OIzB?wU*goPkYY{|U_I!r&BgJ9n&jpiWOFLXu=5dNs+0!DKX
zZbfebA)13Ag8l0pglGW*E2<|D;y4I=XSAO0jIs&2V$UmD1wyn8g4kn=R)G+$vV>?3
zLfxCWcYO1~-MfS)<OaA5l|yb2%|STH_ly67I0sOaAVhNzZj(Wvc!Gp~yx8N2;ULUI
z9bq4%vV<4`LjScKgcuIOe6%DNh>=}@=QwOURMxQEdJ;+Oaj2JgF)GDlWW}{IUF9qn
zqf$JED?ZqrBEToy1!DN<<A=$)3&e26`I_D{5u*<vl#0i2#qWSngc$`*r{b|(@!L^H
zipQ!(Kb9-bn8-e3x#A1Zk`$-sz>%_{q;hT<omomfDc%L|T{m}PRf@;Tii^GQSk;Kf
zsuYi9WcFL0tNkFc@4H;_SmFDuj4K|?6$ewi==wf@P%0j)Qk-T6Z2ih39>*28XSH#v
z5swoizFJ(0jN^(gLT`dEPFB2tk6Iizd5YmXFs;(VdkF}d2Ur~sg_zt46#En(rvf5Q
z20~2naVj9<R6xXWAhNsEPm~6}o<r^z$AJ*r)4?2!I1Yv%ZFKpD0Sthn1S5`vai^>X
zO^Mjyc;Gv(Mmz^&G3v+);vHZRqj(O6xLOh;xAuTIccC>|Lc9z}KPau)cpsfvW<4p*
z6FsrqbIbzqDgfeT0K}bT@hSk~RRF|;qjR&D1|nWqLj4r3JZ`*0i*LB^(_$ZB{4L*^
zCsd-{;w2F37`D9VPVJ@0TCOoqjVI4v{53bY1+%SQ6n%4X&};B1#_q%Y?f21*A&ytx
zDN4NE6TpuiKA3>Npr8tEM^>R|hWjAtq1NsN;%<0H=l=<B{%*kIsogb=M5UUOi=Vh~
zWmIM0OAl&UQvBx6>H7S39NswS^IRMrIELULIHuvCOAR!|(&g@TIOw|W1{}2G{ss;=
z9Dy)LT7uBUs{;LOd>y_}Uu>FXGoaj3JuOs67)#A2i>cfyjnJ3UlQr;UnL%?)4YV4|
z#ZmXhxNi5qc3i{XPq)20e9v)>JL=nBZ3wg>(1t)80&NJiA<%|E8v<<zv?0)jKpO&W
z2>fqGpr!S{+tH7YuG57Fu3UrlfAW=AY5l(!2W^|s`o9PV?flTKKeW?dhJ(HVKx=VY
z+tXzeTKCgNE8SdlCl1;VSc-%82cE#8+z+6=1bT_}I^94jUd{cF027jf_9Mj4Mle5A
z5lPxcpl;($<{5ZkGoFsesZ#5<R~rIt2(%&4hCmwvZ3wg>(1t)80&NJiA<%|E8v_6P
z5TF$?EtqM|P3vz@99}qRO-<MIX{}EWJfOuit=Vb)PG3l-bw91~>AncM=1=SVP#pA~
zDq8E)egJ*FguZD(_m|N<_jLW9?zyJLIo*9L;fTZ$g(DhA3=X<qiEiD&Edu<(7K!-Z
z14j~$WE?$l=y3GHk%A)?M;eZF92qz=ab)4h#?c!G-K^6W2i@`3AIAV3H{i&@k&EMR
z+_;g4|M@rya16q6BaXp1=)MN}oW2=297iFJ5jaNT7=@z<2Yr4G2mSw__$tPaV2Pi>
z5<ka7KeODL7rySrZ+;=&$&Mr~of)g=XAY%!hjWU~xZv8p;~K)sUO67z&G?})`k6oz
z{<rppudh1zlML6}f6PMB(vywBkNt?>(I(x8;zx<Z@4C?s=h}aNv3aTq;7>k8{&T(j
i2NF4Q9=tqZbte3<8Ob1iwybsX^!`84e<(4Q`TrN(-Vdq(

diff --git a/requirements.txt b/requirements.txt
index 22b50997551aaee3e9068495f218cd70c3ac8831..84fe60634b67d19edede4ebf028c9edb24a95930 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,13 +1 @@
-pandas
-scikit-learn
-numpy
-matplotlib
-seaborn
-train_test_split
-RandomForestRegressor
-LinearRegression
-mean_squared_error
-StandardScaler
-scipy.stats
-norm
-math
+# The project intentionally relies on the Python standard library.
diff --git a/src/__init__.py b/src/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
diff --git a/src/data/__init__.py b/src/data/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
diff --git a/src/data/loaders.py b/src/data/loaders.py
new file mode 100644
index 0000000000000000000000000000000000000000..8f3167798ee714589a496f462dce36224f200849
--- /dev/null
+++ b/src/data/loaders.py
@@ -0,0 +1,76 @@
+"""Data loading utilities for the sports prediction pipeline."""
+from __future__ import annotations
+
+import csv
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import List, Sequence
+
+from src.utils.paths import data_dir
+
+
+@dataclass
+class PlayerGameLog:
+    """Structured representation of a single player game."""
+
+    player: str
+    date: datetime
+    team: str
+    opponent: str
+    home: bool
+    bet_line: float
+    odds: int
+    points: float
+    rebounds: float
+    assists: float
+
+    @classmethod
+    def from_row(cls, row: dict[str, str]) -> "PlayerGameLog":
+        return cls(
+            player=row["player"],
+            date=datetime.fromisoformat(row["date"]),
+            team=row["team"],
+            opponent=row["opponent"],
+            home=row.get("home", "0") in {"1", "true", "True"},
+            bet_line=float(row["bet_line"]),
+            odds=int(row["odds"]),
+            points=float(row["points"]),
+            rebounds=float(row["rebounds"]),
+            assists=float(row["assists"]),
+        )
+
+
+def load_player_game_logs(path: Path | None = None) -> List[PlayerGameLog]:
+    """Load player game logs from CSV into dataclass records."""
+
+    dataset = path or data_dir() / "sample_games.csv"
+    if not dataset.exists():
+        raise FileNotFoundError(
+            "Could not locate dataset. Provide a valid path or place a CSV in"
+            f" {data_dir()} named 'sample_games.csv'."
+        )
+
+    with dataset.open(newline="") as fh:
+        reader = csv.DictReader(fh)
+        return [PlayerGameLog.from_row(row) for row in reader]
+
+
+def to_dicts(logs: Sequence[PlayerGameLog]) -> List[dict[str, object]]:
+    """Convert dataclass records into dictionaries for downstream use."""
+
+    return [
+        {
+            "player": log.player,
+            "date": log.date,
+            "team": log.team,
+            "opponent": log.opponent,
+            "home": int(log.home),
+            "bet_line": log.bet_line,
+            "odds": log.odds,
+            "points": log.points,
+            "rebounds": log.rebounds,
+            "assists": log.assists,
+        }
+        for log in logs
+    ]
diff --git a/src/features/__init__.py b/src/features/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
diff --git a/src/features/engineering.py b/src/features/engineering.py
new file mode 100644
index 0000000000000000000000000000000000000000..3ede27d2a72f7b98500edecde37450cbfe9147e5
--- /dev/null
+++ b/src/features/engineering.py
@@ -0,0 +1,55 @@
+"""Feature engineering helpers for model-ready datasets."""
+from __future__ import annotations
+
+from collections import defaultdict
+from typing import Dict, List, Sequence
+
+from src.data.loaders import PlayerGameLog
+
+
+def add_rolling_features(
+    logs: Sequence[PlayerGameLog], window: int = 3
+) -> List[Dict[str, object]]:
+    """Compute rolling averages for each player and return feature dicts."""
+
+    by_player: Dict[str, List[PlayerGameLog]] = defaultdict(list)
+    for log in sorted(logs, key=lambda row: (row.player, row.date)):
+        by_player[log.player].append(log)
+
+    feature_rows: List[Dict[str, object]] = []
+    for player, entries in by_player.items():
+        history: List[PlayerGameLog] = []
+        for entry in entries:
+            rolling_points = _rolling_average([g.points for g in history], window)
+            rolling_rebounds = _rolling_average([g.rebounds for g in history], window)
+            rolling_assists = _rolling_average([g.assists for g in history], window)
+
+            feature_rows.append(
+                {
+                    "player": entry.player,
+                    "date": entry.date,
+                    "team": entry.team,
+                    "opponent": entry.opponent,
+                    "home": int(entry.home),
+                    "bet_line": entry.bet_line,
+                    "odds": entry.odds,
+                    "points": entry.points,
+                    "rebounds": entry.rebounds,
+                    "assists": entry.assists,
+                    "points_rolling": rolling_points,
+                    "rebounds_rolling": rolling_rebounds,
+                    "assists_rolling": rolling_assists,
+                }
+            )
+
+            history.append(entry)
+
+    return feature_rows
+
+
+def _rolling_average(values: Sequence[float], window: int) -> float:
+    if not values:
+        return 0.0
+
+    subset = values[-window:]
+    return sum(subset) / len(subset)
diff --git a/src/models/__init__.py b/src/models/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
diff --git a/src/models/forest.py b/src/models/forest.py
new file mode 100644
index 0000000000000000000000000000000000000000..ed277884143cf08a0d422bb7da02080acbc671cf
--- /dev/null
+++ b/src/models/forest.py
@@ -0,0 +1,111 @@
+"""Lightweight random forest implementation without third-party dependencies."""
+from __future__ import annotations
+
+import math
+import random
+from dataclasses import dataclass
+from typing import Iterable, List, Sequence
+
+
+@dataclass
+class DecisionStump:
+    feature: str
+    threshold: float
+    left_value: float
+    right_value: float
+
+    def predict(self, row: dict[str, float]) -> float:
+        value = row.get(self.feature, 0.0)
+        if value <= self.threshold:
+            return self.left_value
+        return self.right_value
+
+
+class RandomForestRegressor:
+    """A tiny, deterministic random forest for educational purposes."""
+
+    def __init__(self, n_estimators: int = 50, random_state: int | None = None) -> None:
+        self.n_estimators = n_estimators
+        self.random_state = random_state
+        self._trees: List[DecisionStump] = []
+        self._random = random.Random(random_state)
+
+    def fit(self, rows: Sequence[dict[str, float]], targets: Sequence[float]) -> None:
+        if not rows:
+            raise ValueError("Cannot train model on empty dataset")
+
+        feature_names = [name for name in rows[0].keys() if name != "bias"]
+        self._trees = []
+
+        for _ in range(self.n_estimators):
+            tree = self._build_stump(rows, targets, feature_names)
+            self._trees.append(tree)
+
+    def _build_stump(
+        self,
+        rows: Sequence[dict[str, float]],
+        targets: Sequence[float],
+        feature_names: Sequence[str],
+    ) -> DecisionStump:
+        indices = [self._random.randrange(len(rows)) for _ in range(len(rows))]
+        best_feature = feature_names[0]
+        best_threshold = rows[indices[0]][best_feature]
+        best_error = math.inf
+        best_left = _average(targets)
+        best_right = best_left
+
+        sampled_features = self._random.sample(feature_names, k=max(1, int(math.sqrt(len(feature_names)))))
+
+        for feature in sampled_features:
+            values = sorted({rows[i][feature] for i in indices})
+            for threshold in values:
+                left_targets = [targets[i] for i in indices if rows[i][feature] <= threshold]
+                right_targets = [targets[i] for i in indices if rows[i][feature] > threshold]
+                if not left_targets or not right_targets:
+                    continue
+
+                error = _variance(left_targets) + _variance(right_targets)
+                if error < best_error:
+                    best_error = error
+                    best_feature = feature
+                    best_threshold = threshold
+                    best_left = _average(left_targets)
+                    best_right = _average(right_targets)
+
+        return DecisionStump(best_feature, best_threshold, best_left, best_right)
+
+    def predict(self, rows: Sequence[dict[str, float]]) -> List[float]:
+        if not self._trees:
+            raise RuntimeError("Model has not been trained yet")
+
+        predictions = []
+        for row in rows:
+            tree_outputs = [tree.predict(row) for tree in self._trees]
+            predictions.append(sum(tree_outputs) / len(tree_outputs))
+        return predictions
+
+    def __getstate__(self) -> dict:
+        return {
+            "n_estimators": self.n_estimators,
+            "random_state": self.random_state,
+            "trees": self._trees,
+        }
+
+    def __setstate__(self, state: dict) -> None:
+        self.n_estimators = state["n_estimators"]
+        self.random_state = state["random_state"]
+        self._trees = state["trees"]
+        self._random = random.Random(self.random_state)
+
+
+def _average(values: Sequence[float]) -> float:
+    if not values:
+        return 0.0
+    return sum(values) / len(values)
+
+
+def _variance(values: Sequence[float]) -> float:
+    if not values:
+        return 0.0
+    mean = _average(values)
+    return sum((value - mean) ** 2 for value in values) / len(values)
diff --git a/src/models/pipeline.py b/src/models/pipeline.py
new file mode 100644
index 0000000000000000000000000000000000000000..9e0a2aba1932962862b031f02a9ce0f6d6d3d3e0
--- /dev/null
+++ b/src/models/pipeline.py
@@ -0,0 +1,168 @@
+"""Model training pipeline built on top of the lightweight random forest."""
+from __future__ import annotations
+
+import json
+import math
+import pickle
+import random
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Dict, List, Sequence, Tuple
+
+from src.data.loaders import PlayerGameLog, load_player_game_logs
+from src.features.engineering import add_rolling_features
+from src.models.forest import RandomForestRegressor
+
+
+NUMERIC_FEATURES = [
+    "rebounds",
+    "assists",
+    "bet_line",
+    "home",
+    "points_rolling",
+    "rebounds_rolling",
+    "assists_rolling",
+]
+TARGET = "points"
+
+
+@dataclass
+class ModelArtifacts:
+    model: RandomForestRegressor
+    feature_names: Tuple[str, ...]
+    metrics: Dict[str, float]
+    predictions: List[dict[str, float]]
+
+
+def _prepare_features(records: Sequence[dict[str, object]]) -> Tuple[List[dict[str, float]], List[float], List[dict[str, object]]]:
+    features: List[dict[str, float]] = []
+    targets: List[float] = []
+    metadata: List[dict[str, object]] = []
+    for record in records:
+        feature_row = {name: float(record[name]) for name in NUMERIC_FEATURES}
+        features.append(feature_row)
+        targets.append(float(record[TARGET]))
+        metadata.append(record)
+    return features, targets, metadata
+
+
+def _train_test_split(
+    features: Sequence[dict[str, float]],
+    targets: Sequence[float],
+    *,
+    test_size: float = 0.3,
+    random_state: int = 42,
+) -> Tuple[List[dict[str, float]], List[dict[str, float]], List[float], List[float], List[int], List[int]]:
+    size = len(features)
+    indices = list(range(size))
+    rng = random.Random(random_state)
+    rng.shuffle(indices)
+    split = max(1, int(size * (1 - test_size)))
+    train_idx = indices[:split]
+    test_idx = indices[split:]
+
+    X_train = [features[i] for i in train_idx]
+    y_train = [targets[i] for i in train_idx]
+    X_test = [features[i] for i in test_idx]
+    y_test = [targets[i] for i in test_idx]
+    return X_train, X_test, y_train, y_test, train_idx, test_idx
+
+
+def _rmse(y_true: Sequence[float], y_pred: Sequence[float]) -> float:
+    return math.sqrt(sum((a - b) ** 2 for a, b in zip(y_true, y_pred)) / len(y_true))
+
+
+def _mae(y_true: Sequence[float], y_pred: Sequence[float]) -> float:
+    return sum(abs(a - b) for a, b in zip(y_true, y_pred)) / len(y_true)
+
+
+def _sigmoid(value: float) -> float:
+    return 1.0 / (1.0 + math.exp(-value))
+
+
+def run_training_pipeline(
+    logs: Sequence[PlayerGameLog] | None = None, random_state: int = 42
+) -> ModelArtifacts:
+    dataset = logs or load_player_game_logs()
+    records = add_rolling_features(dataset)
+    features, targets, metadata = _prepare_features(records)
+
+    (
+        X_train,
+        X_test,
+        y_train,
+        y_test,
+        train_idx,
+        test_idx,
+    ) = _train_test_split(features, targets, random_state=random_state)
+
+    model = RandomForestRegressor(n_estimators=200, random_state=random_state)
+    model.fit(X_train, y_train)
+    predictions = model.predict(X_test)
+
+    metrics = {
+        "rmse": round(_rmse(y_test, predictions), 3),
+        "mae": round(_mae(y_test, predictions), 3),
+    }
+
+    detailed_predictions: List[dict[str, float]] = []
+    for feature_row, meta, actual, predicted in zip(
+        X_test, [metadata[i] for i in test_idx], y_test, predictions
+    ):
+        margin = predicted - feature_row["bet_line"]
+        prob_over = _sigmoid(margin)
+        odds = float(meta["odds"])
+        payout = odds / 100 if odds >= 0 else 100 / abs(odds)
+        expected_value = prob_over * payout - (1 - prob_over)
+        detailed_predictions.append(
+            {
+                "player": str(meta["player"]),
+                "team": str(meta["team"]),
+                "opponent": str(meta["opponent"]),
+                "bet_line": feature_row["bet_line"],
+                "odds": odds,
+                "actual_points": actual,
+                "predicted_points": round(predicted, 2),
+                "prob_over": round(prob_over, 3),
+                "expected_value": round(expected_value, 3),
+            }
+        )
+
+    return ModelArtifacts(
+        model=model,
+        feature_names=tuple(NUMERIC_FEATURES),
+        metrics=metrics,
+        predictions=detailed_predictions,
+    )
+
+
+def persist_artifacts(artifacts: ModelArtifacts, output_dir: str | Path) -> None:
+    output_path = Path(output_dir)
+    output_path.mkdir(parents=True, exist_ok=True)
+
+    model_path = output_path / "model.pkl"
+    with model_path.open("wb") as fh:
+        pickle.dump(artifacts.model, fh)
+
+    metrics_path = output_path / "metrics.json"
+    with metrics_path.open("w") as fh:
+        json.dump(artifacts.metrics, fh, indent=2)
+
+    predictions_path = output_path / "predictions.csv"
+    fieldnames = [
+        "player",
+        "team",
+        "opponent",
+        "bet_line",
+        "odds",
+        "actual_points",
+        "predicted_points",
+        "prob_over",
+        "expected_value",
+    ]
+    import csv
+
+    with predictions_path.open("w", newline="") as fh:
+        writer = csv.DictWriter(fh, fieldnames=fieldnames)
+        writer.writeheader()
+        writer.writerows(artifacts.predictions)
diff --git a/src/utils/__init__.py b/src/utils/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
diff --git a/src/utils/paths.py b/src/utils/paths.py
new file mode 100644
index 0000000000000000000000000000000000000000..155bb73f4af378fe97b410482145039d82e71fb0
--- /dev/null
+++ b/src/utils/paths.py
@@ -0,0 +1,21 @@
+"""Utility helpers for working with project paths."""
+from __future__ import annotations
+
+from pathlib import Path
+
+
+def get_project_root() -> Path:
+    """Return the absolute path to the project root directory."""
+    return Path(__file__).resolve().parents[2]
+
+
+def data_dir() -> Path:
+    """Return the directory where raw data is stored."""
+    return get_project_root() / "data" / "raw"
+
+
+def outputs_dir() -> Path:
+    """Return the directory where pipeline outputs should be written."""
+    path = get_project_root() / "outputs"
+    path.mkdir(parents=True, exist_ok=True)
+    return path
diff --git a/tests/test_pipeline.py b/tests/test_pipeline.py
new file mode 100644
index 0000000000000000000000000000000000000000..be24b9bbd0f1a0fd9a2b471822aac1c69ff0f088
--- /dev/null
+++ b/tests/test_pipeline.py
@@ -0,0 +1,36 @@
+"""Unit tests for the sports prediction training pipeline."""
+from __future__ import annotations
+
+import unittest
+
+from src.data.loaders import load_player_game_logs
+from src.features.engineering import add_rolling_features
+from src.models.pipeline import run_training_pipeline
+
+
+class PipelineTests(unittest.TestCase):
+    def test_load_player_game_logs(self) -> None:
+        logs = load_player_game_logs()
+        self.assertTrue(logs)
+        self.assertEqual(logs[0].player, "Alice")
+
+    def test_add_rolling_features_creates_columns(self) -> None:
+        logs = load_player_game_logs()
+        features = add_rolling_features(logs)
+        first_row = features[0]
+        self.assertIn("points_rolling", first_row)
+        self.assertIn("rebounds_rolling", first_row)
+        self.assertIn("assists_rolling", first_row)
+
+    def test_training_pipeline_returns_metrics_and_predictions(self) -> None:
+        logs = load_player_game_logs()
+        artifacts = run_training_pipeline(logs, random_state=0)
+
+        self.assertIn("rmse", artifacts.metrics)
+        self.assertIn("mae", artifacts.metrics)
+        self.assertTrue(artifacts.predictions)
+        self.assertIn("expected_value", artifacts.predictions[0])
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/train.py b/train.py
new file mode 100644
index 0000000000000000000000000000000000000000..0cd1ab65d5a689a687aaf8dafba1fecfa64b1ea7
--- /dev/null
+++ b/train.py
@@ -0,0 +1,52 @@
+"""Command line entry point to train the sports prediction model."""
+from __future__ import annotations
+
+import argparse
+from pathlib import Path
+
+from src.data.loaders import load_player_game_logs
+from src.models.pipeline import persist_artifacts, run_training_pipeline
+from src.utils.paths import outputs_dir
+
+
+def parse_args() -> argparse.Namespace:
+    parser = argparse.ArgumentParser(description=__doc__)
+    parser.add_argument(
+        "--data",
+        type=Path,
+        default=None,
+        help="Optional path to a CSV file containing player game logs.",
+    )
+    parser.add_argument(
+        "--output",
+        type=Path,
+        default=outputs_dir(),
+        help="Directory where model artifacts will be stored.",
+    )
+    parser.add_argument(
+        "--random-state",
+        type=int,
+        default=42,
+        help="Random seed used for the train/test split and model training.",
+    )
+    return parser.parse_args()
+
+
+def format_metrics(metrics: dict[str, float]) -> str:
+    return "\n".join(f"{key}: {value}" for key, value in metrics.items())
+
+
+def main() -> None:
+    args = parse_args()
+    data = load_player_game_logs(args.data)
+
+    artifacts = run_training_pipeline(data, random_state=args.random_state)
+    persist_artifacts(artifacts, str(args.output))
+
+    print("Training complete. Metrics:")
+    print(format_metrics(artifacts.metrics))
+    print(f"Predictions saved to: {args.output / 'predictions.csv'}")
+
+
+if __name__ == "__main__":
+    main()


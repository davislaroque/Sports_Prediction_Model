{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5eb97b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version #1\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # Load and preprocess data\n",
    "# def load_and_preprocess(file_path):\n",
    "#     data = pd.read_csv(file_path)\n",
    "\n",
    "#     # Handle missing values (basic example: fill with mean)\n",
    "#     data.fillna(data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "#     # Filter for the most recent season\n",
    "#     if 'season' in data.columns:\n",
    "#         most_recent_season = data['season'].max()\n",
    "#         data = data[data['season'] == most_recent_season]\n",
    "#     else:\n",
    "#         raise ValueError(\"The dataset does not contain a 'season' column.\")\n",
    "\n",
    "    \n",
    "#     features = [\n",
    "#         'age', 'experience', 'fg_per_game', 'fga_per_game', 'x3p_per_game',\n",
    "#         'x2p_per_game', 'ft_per_game', 'trb_per_game', 'ast_per_game', 'pts_per_game'\n",
    "#     ]\n",
    "\n",
    "#     return data, features\n",
    "\n",
    "# # Normalize features\n",
    "# def normalize_features(X):\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     return X_scaled, scaler\n",
    "\n",
    "# # Predict player performance\n",
    "# def predict_player_performance(data, model, scaler, player_name, target):\n",
    "#     player_data = data[data['player'] == player_name]\n",
    "#     if player_data.empty:\n",
    "#         return f\"Player {player_name} not found in the dataset.\"\n",
    "\n",
    "#     features = [\n",
    "#         'age', 'experience', 'fg_per_game', 'fga_per_game', 'x3p_per_game',\n",
    "#         'x2p_per_game', 'ft_per_game', 'trb_per_game', 'ast_per_game', 'pts_per_game'\n",
    "#     ]\n",
    "\n",
    "#     player_features = player_data[features].values\n",
    "#     player_features_scaled = scaler.transform(player_features)\n",
    "#     predicted_value = model.predict(player_features_scaled)\n",
    "\n",
    "#     return f\"Predicted {target} for {player_name}: {predicted_value[0]:.2f}\"\n",
    "\n",
    "# # Train the model for a specific target\n",
    "# def train_model(data, features, target):\n",
    "#     X = data[features]\n",
    "#     y = data[target]\n",
    "\n",
    "#     # Normalize features\n",
    "#     X_scaled, scaler = normalize_features(X)\n",
    "\n",
    "#     # Train the model\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(X_scaled, y)\n",
    "\n",
    "#     return model, scaler\n",
    "\n",
    "# # Main workflow\n",
    "# def main():\n",
    "#     # File path to dataset\n",
    "#     file_path = '/Users/davislaroque/Desktop/NBA Project/archive/Player Per Game.csv'\n",
    "#     # Load and preprocess data\n",
    "#     data, features = load_and_preprocess(file_path)\n",
    "\n",
    "    \n",
    "#     # CHANGE TARGET VARIABLE\n",
    "#     target = 'trb_per_game'\n",
    "#      # CHANGE PLAYER NAME\n",
    "#     player_name = \"Zach Edey\" \n",
    "\n",
    "    \n",
    "#     # Train the model for the specified target\n",
    "#     model, scaler = train_model(data, features, target)\n",
    "\n",
    "#     result = predict_player_performance(data, model, scaler, player_name, target)\n",
    "#     print(result)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02ba2c27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Version #2\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import r2_score  # Import r2_score from sklearn.metrics\n",
    "\n",
    "\n",
    "# # Mapping from team abbreviations to full team names\n",
    "# team_abbreviation_to_name = {\n",
    "#     'ATL': 'Atlanta Hawks',\n",
    "#     'BOS': 'Boston Celtics',\n",
    "#     'BRK': 'Brooklyn Nets',\n",
    "#     'CHO': 'Charlotte Hornets',\n",
    "#     'CHI': 'Chicago Bulls',\n",
    "#     'CLE': 'Cleveland Cavaliers',\n",
    "#     'DAL': 'Dallas Mavericks',\n",
    "#     'DEN': 'Denver Nuggets',\n",
    "#     'DET': 'Detroit Pistons',\n",
    "#     'GSW': 'Golden State Warriors',\n",
    "#     'HOU': 'Houston Rockets',\n",
    "#     'IND': 'Indiana Pacers',\n",
    "#     'LAC': 'Los Angeles Clippers',\n",
    "#     'LAL': 'Los Angeles Lakers',\n",
    "#     'MEM': 'Memphis Grizzlies',\n",
    "#     'MIA': 'Miami Heat',\n",
    "#     'MIL': 'Milwaukee Bucks',\n",
    "#     'MIN': 'Minnesota Timberwolves',\n",
    "#     'NOP': 'New Orleans Pelicans',\n",
    "#     'NYK': 'New York Knicks',\n",
    "#     'OKC': 'Oklahoma City Thunder',\n",
    "#     'ORL': 'Orlando Magic',\n",
    "#     'PHI': 'Philadelphia 76ers',\n",
    "#     'PHO': 'Phoenix Suns',\n",
    "#     'POR': 'Portland Trail Blazers',\n",
    "#     'SAC': 'Sacramento Kings',\n",
    "#     'SAS': 'San Antonio Spurs',\n",
    "#     'TOR': 'Toronto Raptors',\n",
    "#     'UTA': 'Utah Jazz',\n",
    "#     'WAS': 'Washington Wizards'\n",
    "# }\n",
    "\n",
    "# # Load and preprocess opponent stats data\n",
    "# def load_opponent_stats(opponent_file):\n",
    "#     opp_stats = pd.read_csv(opponent_file)\n",
    "    \n",
    "#     # A lower rating means better offense (less opponent rebounds etc.)\n",
    "#     opp_stats['defensive_allowance_rating'] = opp_stats['team_defensive_allowance'] = 1 / (\n",
    "#                                             0.5 * opp_stats['opp_trb_per_game'] +\n",
    "#                                             0.3 * opp_stats['opp_stl_per_game'] +\n",
    "#                                             0.2 * opp_stats['opp_blk_per_game']\n",
    "#                                             ) * 10\n",
    "#     # Create a separate dataframe for defensive allowance\n",
    "#     team_defensive_allowance = opp_stats[['team', 'defensive_allowance_rating']]\n",
    "    \n",
    "#     # Clean column values before merging\n",
    "#     team_defensive_allowance['team'] = team_defensive_allowance['team'].str.strip()\n",
    "\n",
    "#     return team_defensive_allowance\n",
    "\n",
    "\n",
    "# # PPG_file = player_per_game\n",
    "# def load_and_preprocess_player_data(ppg_file, team_defensive_allowance):\n",
    "#     ppg_data = pd.read_csv(ppg_file)\n",
    "    \n",
    "#     # Replace the 'tm' abbreviations with full team names\n",
    "#     ppg_data['tm'] = ppg_data['tm'].str.strip().map(team_abbreviation_to_name)\n",
    "    \n",
    "#     # Check if any 'tm' value didn't match a team\n",
    "# #     if ppg_data['tm'].isnull().any():\n",
    "# # #         print(\"Warning: Some team abbreviations did not match a full team name.\")\n",
    "# # #         print(ppg_data[ppg_data['tm'].isnull()][['player', 'tm']])\n",
    "    \n",
    "#     # Merge the player data with the team defensive allowance, using 'tm' from ppg_data and 'team' from team_defensive_allowance\n",
    "#     ppg_data = pd.merge(ppg_data, team_defensive_allowance, how='left', left_on='tm', right_on='team')\n",
    "\n",
    "\n",
    "#     # Handle missing values (basic example: fill with mean of each column)\n",
    "#     ppg_data.fillna(ppg_data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "#     # Filter for the most recent season\n",
    "#     if 'season' in ppg_data.columns:\n",
    "#         most_recent_season = ppg_data['season'].max()\n",
    "#         ppg_data = ppg_data[ppg_data['season'] == most_recent_season]\n",
    "#     else:\n",
    "#         raise ValueError(\"The dataset does not contain a 'season' column.\")\n",
    "    \n",
    "#     features = [\n",
    "#         'age', 'experience', \n",
    "#         'x2p_per_game', 'ft_per_game', 'trb_per_game', 'ast_per_game', 'defensive_allowance_rating',\n",
    "#         'mp_per_game', 'fg_per_game', 'fga_per_game', 'fg_percent', 'x3p_per_game', 'x3pa_per_game', \n",
    "#         'x3p_percent', 'x2p_per_game', 'x2pa_per_game', 'x2p_percent', 'e_fg_percent', 'ft_per_game',\n",
    "#         'fta_per_game', 'ft_percent', 'orb_per_game', 'drb_per_game', 'stl_per_game', \n",
    "#         'blk_per_game', 'tov_per_game', 'pf_per_game'\n",
    "#     ]\n",
    "\n",
    "#     return ppg_data, features\n",
    "\n",
    "# # Normalize features\n",
    "# def normalize_features(X):\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     return X_scaled, scaler\n",
    "\n",
    "# # Predict player performance\n",
    "# def predict_player_performance(data, model, scaler, player_name, target):\n",
    "#     ppg_data = data[data['player'] == player_name]\n",
    "#     if ppg_data.empty:\n",
    "#         return f\"Player {player_name} not found in the dataset.\"\n",
    "\n",
    "#     features = [\n",
    "#         'age', 'experience', \n",
    "#         'x2p_per_game', 'ft_per_game', 'trb_per_game', 'ast_per_game', 'defensive_allowance_rating',\n",
    "#         'mp_per_game', 'fg_per_game', 'fga_per_game', 'fg_percent', 'x3p_per_game', 'x3pa_per_game', \n",
    "#         'x3p_percent', 'x2p_per_game', 'x2pa_per_game', 'x2p_percent', 'e_fg_percent', 'ft_per_game',\n",
    "#         'fta_per_game', 'ft_percent', 'orb_per_game', 'drb_per_game', 'stl_per_game', \n",
    "#         'blk_per_game', 'tov_per_game', 'pf_per_game'\n",
    "#     ]\n",
    "\n",
    "#     player_features = ppg_data[features].values\n",
    "#     player_features_scaled = scaler.transform(player_features)\n",
    "#     predicted_value = model.predict(player_features_scaled)\n",
    "\n",
    "#     return f\"Predicted {target} for {player_name}: {predicted_value[0]:.2f}\"\n",
    "\n",
    "# # Train the model for a specific target\n",
    "# def train_model(data, features, target):\n",
    "#     X = data[features]\n",
    "#     y = data[target]\n",
    "\n",
    "#     # Handle missing values in X (if any)\n",
    "#     X.fillna(X.mean(), inplace=True)  # Fill missing values with column means\n",
    "\n",
    "#     # Normalize features\n",
    "#     X_scaled, scaler = normalize_features(X)\n",
    "\n",
    "#     # Train the model\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(X_scaled, y)\n",
    "\n",
    "#     return model, scaler\n",
    "\n",
    "# # Main workflow\n",
    "# def main():\n",
    "#     # File paths\n",
    "#     opponent_file = '/Users/davislaroque/Desktop/NBA Project/archive/Opponent Stats Per Game.csv'\n",
    "#     ppg_file = '/Users/davislaroque/Desktop/NBA Project/archive/Player Per Game.csv'\n",
    "\n",
    "#     # Load and preprocess data\n",
    "#     team_defensive_allowance = load_opponent_stats(opponent_file)\n",
    "#     player_data, features = load_and_preprocess_player_data(ppg_file, team_defensive_allowance)\n",
    "\n",
    "#     # CHANGE TARGET VARIABLE\n",
    "#     target = 'pts_per_game'\n",
    "#     # CHANGE PLAYER NAME\n",
    "#     player_name = \"Austin Reaves\"\n",
    "\n",
    "#     # Train the model for the specified target\n",
    "#     model, scaler = train_model(player_data, features, target)\n",
    "\n",
    "#     # Predict player performance\n",
    "#     result = predict_player_performance(player_data, model, scaler, player_name, target)\n",
    "#     print(result)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fabbc06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Version #3\n",
    "\n",
    "# from scipy.stats import norm\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# team_abbreviation_to_name = {\n",
    "#     'ATL': 'Atlanta Hawks',\n",
    "#     'BOS': 'Boston Celtics',\n",
    "#     'BRK': 'Brooklyn Nets',\n",
    "#     'CHO': 'Charlotte Hornets',\n",
    "#     'CHI': 'Chicago Bulls',\n",
    "#     'CLE': 'Cleveland Cavaliers',\n",
    "#     'DAL': 'Dallas Mavericks',\n",
    "#     'DEN': 'Denver Nuggets',\n",
    "#     'DET': 'Detroit Pistons',\n",
    "#     'GSW': 'Golden State Warriors',\n",
    "#     'HOU': 'Houston Rockets',\n",
    "#     'IND': 'Indiana Pacers',\n",
    "#     'LAC': 'Los Angeles Clippers',\n",
    "#     'LAL': 'Los Angeles Lakers',\n",
    "#     'MEM': 'Memphis Grizzlies',\n",
    "#     'MIA': 'Miami Heat',\n",
    "#     'MIL': 'Milwaukee Bucks',\n",
    "#     'MIN': 'Minnesota Timberwolves',\n",
    "#     'NOP': 'New Orleans Pelicans',\n",
    "#     'NYK': 'New York Knicks',\n",
    "#     'OKC': 'Oklahoma City Thunder',\n",
    "#     'ORL': 'Orlando Magic',\n",
    "#     'PHI': 'Philadelphia 76ers',\n",
    "#     'PHO': 'Phoenix Suns',\n",
    "#     'POR': 'Portland Trail Blazers',\n",
    "#     'SAC': 'Sacramento Kings',\n",
    "#     'SAS': 'San Antonio Spurs',\n",
    "#     'TOR': 'Toronto Raptors',\n",
    "#     'UTA': 'Utah Jazz',\n",
    "#     'WAS': 'Washington Wizards'\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# #Function that loads team file \n",
    "# def load_and_preprocess_player_data(ppg_file, team_defensive_allowance):\n",
    "#     ppg_data = pd.read_csv(ppg_file)\n",
    "    \n",
    "#     # Replace the 'tm' abbreviations with full team names\n",
    "#     ppg_data['tm'] = ppg_data['tm'].str.strip().map(team_abbreviation_to_name)\n",
    "    \n",
    "    \n",
    "#     # Merge the player data with the team defensive allowance, using 'tm' from ppg_data and 'team' from team_defensive_allowance\n",
    "#     ppg_data = pd.merge(ppg_data, team_defensive_allowance, how='left', left_on='tm', right_on='team')\n",
    "\n",
    "\n",
    "#     # Handle missing values (basic example: fill with mean of each column)\n",
    "#     ppg_data.fillna(ppg_data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "#     # Filter for the most recent season\n",
    "#     if 'season' in ppg_data.columns:\n",
    "#         most_recent_season = ppg_data['season'].max()\n",
    "#         ppg_data = ppg_data[ppg_data['season'] == most_recent_season]\n",
    "#     else:\n",
    "#         raise ValueError(\"The dataset does not contain a 'season' column.\")\n",
    "    \n",
    "#     features = [\n",
    "#     'age', 'experience', \n",
    "#     'x2p_per_game', 'ft_per_game', 'trb_per_game', 'ast_per_game', 'defensive_allowance_rating',\n",
    "#     'mp_per_game', 'fg_per_game', 'fga_per_game', 'fg_percent', 'x3p_per_game', 'x3pa_per_game', \n",
    "#     'x3p_percent', 'x2pa_per_game', 'x2p_percent', 'e_fg_percent', \n",
    "#     'fta_per_game', 'ft_percent', 'orb_per_game', 'drb_per_game', 'stl_per_game', \n",
    "#     'blk_per_game', 'tov_per_game', 'pf_per_game'\n",
    "# ]\n",
    "\n",
    "#     return ppg_data, features\n",
    "\n",
    "\n",
    "# def predict_with_prediction_interval(model, scaler, X_train_scaled, sample_features, alpha=0.05):\n",
    "#     from scipy.stats import norm\n",
    "\n",
    "#     # Scale the sample features (must be 2D)\n",
    "#     sample_features_scaled = scaler.transform(sample_features)\n",
    "#     predicted_value = model.predict(sample_features_scaled)[0]\n",
    "\n",
    "#     # z-score for the desired confidence level\n",
    "#     z_score = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "#     # Calculate (X^T X)^-1\n",
    "#     XTX_inv = np.linalg.inv(X_train_scaled.T @ X_train_scaled)\n",
    "\n",
    "#     # Calculate the variance for the new prediction\n",
    "#     x_0 = sample_features_scaled[0].reshape(-1, 1)  # column vector\n",
    "#     variance = model.sigma_**2 + (x_0.T @ XTX_inv @ x_0)[0, 0]\n",
    "\n",
    "#     # Margin of error\n",
    "#     margin_error = z_score * np.sqrt(variance)\n",
    "\n",
    "#     lower_bound = predicted_value - margin_error\n",
    "#     upper_bound = predicted_value + margin_error\n",
    "\n",
    "#     return predicted_value, lower_bound, upper_bound\n",
    "\n",
    "\n",
    "# #Function that loads opponents stats\n",
    "# def load_opponent_stats(opponent_file):\n",
    "#     opp_stats = pd.read_csv(opponent_file)\n",
    "    \n",
    "#     # A lower rating means better offense (less opponent rebounds etc.)\n",
    "#     opp_stats['defensive_allowance_rating'] = opp_stats['team_defensive_allowance'] = 1 / (\n",
    "#                                             0.5 * opp_stats['opp_trb_per_game'] +\n",
    "#                                             0.3 * opp_stats['opp_stl_per_game'] +\n",
    "#                                             0.2 * opp_stats['opp_blk_per_game']\n",
    "#                                             ) * 10\n",
    "#     # Create a separate dataframe for defensive allowance\n",
    "#     team_defensive_allowance = opp_stats[['team', 'defensive_allowance_rating']]\n",
    "    \n",
    "#     # Clean column values before merging\n",
    "#     team_defensive_allowance = team_defensive_allowance.copy()\n",
    "#     team_defensive_allowance['team'] = team_defensive_allowance['team'].str.strip()\n",
    "\n",
    "#     return team_defensive_allowance\n",
    "\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     # File paths\n",
    "#     opponent_file = '/Users/davislaroque/Desktop/NBA Project/archive/Opponent Stats Per Game.csv'\n",
    "#     ppg_file = '/Users/davislaroque/Desktop/NBA Project/archive-4-15-25/Player Per Game.csv'\n",
    "    \n",
    "#     # CHANGE TARGET VARIABLE\n",
    "#     target = 'trb_per_game'\n",
    "#     # CHANGE PLAYER NAME\n",
    "#     player_name = \"Bam Adebayo\"\n",
    "    \n",
    "#     alpha = 0.05  # 95% prediction interval\n",
    "\n",
    "#     # Load and preprocess data\n",
    "#     team_defensive_allowance = load_opponent_stats(opponent_file)\n",
    "#     player_data, features = load_and_preprocess_player_data(ppg_file, team_defensive_allowance)\n",
    "\n",
    "#     # Train model\n",
    "#     model, scaler = train_model_with_error_estimation(player_data, features, target)\n",
    "\n",
    "#     # Scale full training set (needed for prediction interval)\n",
    "#     X_train_scaled, _ = normalize_features(player_data[features])\n",
    "\n",
    "#     # Grab the player row\n",
    "#     player_row = player_data[player_data['player'] == player_name]\n",
    "#     if player_row.empty:\n",
    "#         print(f\"Player {player_name} not found in the dataset.\")\n",
    "#         return\n",
    "\n",
    "#     # Grab player features\n",
    "#     sample_features = player_row[features].values[:1]\n",
    "\n",
    "#     # Get prediction interval\n",
    "#     predicted_value, lower_bound, upper_bound = predict_with_prediction_interval(\n",
    "#         model, scaler, X_train_scaled, sample_features, alpha=alpha\n",
    "#     )\n",
    "\n",
    "#     # Print result\n",
    "#     print(f\"Predicted {target} for {player_name}: {predicted_value:.2f}\")\n",
    "#     print(f\"If {player_name} plays a game under similar conditions, we expect him to get between {lower_bound:.2f} and {upper_bound:.2f} {target}, with 95% confidence.\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3653b506",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Version #4 with random forest and linear regression\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from scipy.stats import norm\n",
    "\n",
    "# # Normalization helper\n",
    "# def normalize_features(X):\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     return X_scaled, scaler\n",
    "\n",
    "# # Train/Test Split and Model Training with Random Forest and Linear Regression\n",
    "# def train_models_with_comparison(data, features, target):\n",
    "#     X = data[features]\n",
    "#     y = data[target]\n",
    "\n",
    "#     # Fill and scale features\n",
    "#     X = X.fillna(X.mean())\n",
    "#     X_scaled, scaler = normalize_features(X)\n",
    "\n",
    "#     # Split data\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Linear Regression\n",
    "#     lr_model = LinearRegression()\n",
    "#     lr_model.fit(X_train, y_train)\n",
    "#     lr_train_preds = lr_model.predict(X_train)\n",
    "#     lr_residuals = y_train - lr_train_preds\n",
    "#     lr_model.sigma_ = np.std(lr_residuals)\n",
    "    \n",
    "#     # Random Forest\n",
    "#     rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "#     rf_model.fit(X_train, y_train)\n",
    "\n",
    "#     # Evaluate\n",
    "#     lr_mse = mean_squared_error(y_test, lr_model.predict(X_test))\n",
    "#     rf_mse = mean_squared_error(y_test, rf_model.predict(X_test))\n",
    "\n",
    "#     print(f\"Linear Regression MSE: {lr_mse:.4f}\")\n",
    "#     print(f\"Random Forest MSE: {rf_mse:.4f}\")\n",
    "\n",
    "#     return lr_model, rf_model, scaler, X_train, X_test\n",
    "\n",
    "\n",
    "\n",
    "# # Prediction Interval for Linear Regression\n",
    "# def predict_with_prediction_interval(model, scaler, X_train_scaled, sample_features, alpha=0.05):\n",
    "#     sample_features_scaled = scaler.transform(sample_features)\n",
    "#     predicted_value = model.predict(sample_features_scaled)[0]\n",
    "#     z_score = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "#     XTX_inv = np.linalg.inv(X_train_scaled.T @ X_train_scaled)\n",
    "#     x_0 = sample_features_scaled[0].reshape(-1, 1)\n",
    "#     variance = model.sigma_**2 + (x_0.T @ XTX_inv @ x_0)[0, 0]\n",
    "\n",
    "#     margin_error = z_score * np.sqrt(variance)\n",
    "#     lower_bound = predicted_value - margin_error\n",
    "#     upper_bound = predicted_value + margin_error\n",
    "\n",
    "#     return predicted_value, lower_bound, upper_bound\n",
    "\n",
    "\n",
    "# #Function that loads opponents stats\n",
    "# def load_opponent_stats(opponent_file):\n",
    "#     opp_stats = pd.read_csv(opponent_file)\n",
    "    \n",
    "#     # A lower rating means better offense (less opponent rebounds etc.)\n",
    "#     opp_stats['defensive_allowance_rating'] = opp_stats['team_defensive_allowance'] = 1 / (\n",
    "#                                             0.5 * opp_stats['opp_trb_per_game'] +\n",
    "#                                             0.3 * opp_stats['opp_stl_per_game'] +\n",
    "#                                             0.2 * opp_stats['opp_blk_per_game']\n",
    "#                                             ) * 10\n",
    "#     # Create a separate dataframe for defensive allowance\n",
    "#     team_defensive_allowance = opp_stats[['team', 'defensive_allowance_rating']]\n",
    "    \n",
    "#     # Clean column values before merging\n",
    "#     team_defensive_allowance = team_defensive_allowance.copy()\n",
    "#     team_defensive_allowance['team'] = team_defensive_allowance['team'].str.strip()\n",
    "\n",
    "#     return team_defensive_allowance\n",
    "\n",
    "# # Simple prediction from Random Forest\n",
    "# def predict_rf(rf_model, scaler, sample_features):\n",
    "#     sample_scaled = scaler.transform(sample_features)\n",
    "#     return rf_model.predict(sample_scaled)[0]\n",
    "\n",
    "# def load_and_preprocess_player_data(ppg_file, team_defensive_allowance):\n",
    "#     ppg_data = pd.read_csv(ppg_file)\n",
    "    \n",
    "#     # Replace the 'tm' abbreviations with full team names\n",
    "#     ppg_data['tm'] = ppg_data['tm'].str.strip().map(team_abbreviation_to_name)\n",
    "    \n",
    "#     # Interaction terms based on mintues played\n",
    "#     ppg_data['mp_pts'] = ppg_data['mp_per_game'] * ppg_data['pts_per_game']\n",
    "#     ppg_data['mp_trb'] = ppg_data['mp_per_game'] * ppg_data['trb_per_game']\n",
    "    \n",
    "#     # Merge the player data with the team defensive allowance, using 'tm' from ppg_data and 'team' from team_defensive_allowance\n",
    "#     ppg_data = pd.merge(ppg_data, team_defensive_allowance, how='left', left_on='tm', right_on='team')\n",
    "\n",
    "\n",
    "#     # Handle missing values (basic example: fill with mean of each column)\n",
    "#     ppg_data.fillna(ppg_data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "#     # Filter for the most recent season\n",
    "#     if 'season' in ppg_data.columns:\n",
    "#         most_recent_season = ppg_data['season'].max()\n",
    "#         ppg_data = ppg_data[ppg_data['season'] == most_recent_season]\n",
    "#     else:\n",
    "#         raise ValueError(\"The dataset does not contain a 'season' column.\")\n",
    "    \n",
    "#     features = [\n",
    "#     'age', 'experience', \n",
    "#     'x2p_per_game', 'ft_per_game', 'trb_per_game', 'ast_per_game', 'defensive_allowance_rating',\n",
    "#     'mp_per_game', 'fg_per_game', 'fga_per_game', 'fg_percent', 'x3p_per_game', 'x3pa_per_game', \n",
    "#     'x3p_percent', 'x2pa_per_game', 'x2p_percent', 'e_fg_percent', \n",
    "#     'fta_per_game', 'ft_percent', 'orb_per_game', 'drb_per_game', 'stl_per_game', \n",
    "#     'blk_per_game', 'tov_per_game', 'pf_per_game', 'mp_pts', 'mp_trb'\n",
    "# ]\n",
    "\n",
    "#     return ppg_data, features\n",
    "\n",
    "\n",
    "# def calculate_expected_value_from_prediction(\n",
    "#     predicted_points, sigma, sportsbook_line, odds, over=True\n",
    "# ):\n",
    "#     # Calculate probability from normal distribution\n",
    "#     if over:\n",
    "#         prob_win = 1 - norm.cdf(sportsbook_line, loc=predicted_points, scale=sigma)\n",
    "#     else:\n",
    "#         prob_win = norm.cdf(sportsbook_line, loc=predicted_points, scale=sigma)\n",
    "    \n",
    "#     prob_loss = 1 - prob_win\n",
    "\n",
    "#     # Convert odds to decimal\n",
    "#     if odds > 0:\n",
    "#         payout_ratio = odds / 100\n",
    "#     else:\n",
    "#         payout_ratio = 100 / abs(odds)\n",
    "\n",
    "#     # Expected value, assuming $100 bet\n",
    "#     ev = (prob_win * payout_ratio * 100) - (prob_loss * 100)\n",
    "    \n",
    "#     return ev, prob_win\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     # File paths\n",
    "#     opponent_file = '/Users/davislaroque/Desktop/NBA Project/archive/Opponent Stats Per Game.csv'\n",
    "#     ppg_file = '/Users/davislaroque/Desktop/NBA Project/archive-4-15-25/Player Per Game.csv'\n",
    "    \n",
    "#     # CHANGE TARGET VARIABLE\n",
    "#     target = 'pts_per_game'\n",
    "#     # CHANGE PLAYER NAME\n",
    "#     player_name = \"Pascal Siak\"\n",
    "    \n",
    "#     sportsbook_line = 16.5   # CHANGE TO ACTUAL LINE\n",
    "#     odds = -115              # CHANGE TO ACTUAL ODDS\n",
    "    \n",
    "    \n",
    "#     alpha = 0.05  # 95% prediction interval\n",
    "    \n",
    "#     # Load and preprocess data\n",
    "#     team_defensive_allowance = load_opponent_stats(opponent_file)\n",
    "#     player_data, features = load_and_preprocess_player_data(ppg_file, team_defensive_allowance)\n",
    "\n",
    "#     lr_model, rf_model, scaler, X_train_scaled, X_test_scaled = train_models_with_comparison(\n",
    "#     player_data, features, target\n",
    "#     )\n",
    "    \n",
    "#     # Grab the player row\n",
    "#     player_row = player_data[player_data['player'] == player_name]\n",
    "#     if player_row.empty:\n",
    "#         print(f\"Player {player_name} not found in the dataset.\")\n",
    "#         return\n",
    "    \n",
    "    \n",
    "#     # get the average minutes and FGA\n",
    "#     mp_per_game = player_row[\"mp_per_game\"].values[0]\n",
    "#     fga_per_game = player_row[\"fga_per_game\"].values[0]\n",
    "\n",
    "\n",
    "\n",
    "#     # Grab player features\n",
    "#     sample_features = player_row[features].values[:1]\n",
    "\n",
    "#     # Predict with Linear Regression (with Prediction Interval)\n",
    "#     lr_pred, lower, upper = predict_with_prediction_interval(lr_model, scaler, X_train_scaled, sample_features)\n",
    "\n",
    "#     # Predict with Random Forest\n",
    "#     rf_pred = predict_rf(rf_model, scaler, sample_features)\n",
    "    \n",
    "    \n",
    "\n",
    "#     # We'll re-use the LR prediction and sigma\n",
    "#     predicted_points = lr_pred\n",
    "#     sigma = lr_model.sigma_\n",
    "\n",
    "#     ev, prob_win = calculate_expected_value_from_prediction(\n",
    "#         predicted_points, sigma, sportsbook_line, odds, over=True\n",
    "#     )\n",
    "\n",
    "    \n",
    "    \n",
    "#     # Print results\n",
    "#     print(f\"\\n--- {player_name} ---\")\n",
    "#     print(f\"Averaging {mp_per_game:.1f} minutes with {fga_per_game:.1f} FGA/game\\n\")\n",
    "#     print(f\"\\nEV on Over {sportsbook_line} points at {odds} odds: ${ev:.2f}\")\n",
    "#     print(f\"Model-estimated chance of hitting Over: {prob_win * 100:.2f}%\\n\")\n",
    "#     print(f\"Random Forest Prediction: {rf_pred:.2f} {target}\\n\")\n",
    "#     print(f\"Linear Regression Prediction: {lr_pred:.2f} {target}\")\n",
    "#     print(f\"95% Prediction Interval for LR: ({lower:.2f}, {upper:.2f})\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1a83c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# stats_by_game = pd.read_csv('/Users/davislaroque/Desktop/NBA Project/game-by-game-stats/PlayerStatistics2025.csv')\n",
    "\n",
    "# df = pd.DataFrame(stats_by_game)\n",
    "\n",
    "\n",
    "# # Convert the 'date' column to datetime\n",
    "# df['gameDate'] = pd.to_datetime(df['gameDate'])\n",
    "\n",
    "# # Define the date range\n",
    "# start_date = pd.to_datetime('2024-10-22')\n",
    "# end_date = pd.to_datetime('2025-06-22')\n",
    "\n",
    "# # Filter the DataFrame\n",
    "# filtered_df = df[(df['gameDate'] >= start_date) & (stats_by_game['gameDate'] <= end_date)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9064f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load original\n",
    "# team_stats_by_game = pd.read_csv('/Users/davislaroque/Desktop/NBA Project/game-by-game-stats/TeamStatistics.csv')\n",
    "# df = pd.DataFrame(team_stats_by_game)\n",
    "\n",
    "# # Convert 'gameDate' to datetime\n",
    "# df['gameDate'] = pd.to_datetime(df['gameDate'])\n",
    "\n",
    "# # Define the season date range\n",
    "# start_date = pd.to_datetime('2024-10-22')\n",
    "# end_date = pd.to_datetime('2025-06-22')\n",
    "\n",
    "# # Filter to just the 2024-25 season\n",
    "# filtered_df = df[(df['gameDate'] >= start_date) & (df['gameDate'] <= end_date)]\n",
    "\n",
    "# # Save to new file\n",
    "# filtered_df.to_csv('/Users/davislaroque/Desktop/NBA Project/game-by-game-stats/filtered_team_stats.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d86887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/43/qtyjg2710fb7jw4r2dclzgqc0000gn/T/ipykernel_29551/4138483687.py:83: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ppg_data = pd.read_csv(ppg_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 1.3353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davislaroque/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adjustment Breakdown:\n",
      "  • Opponent adjustment: +1.35 reboundsTotal\n",
      "  • Pace adjustment: +0.05 reboundsTotal (Game Pace 101.0, team_pace = 99.88, opponent_pace = 102.16, League Pace 100.0)\n",
      "  • Away game adjustment: -0.34 reboundsTotal\n",
      "Monte Carlo OVER Prob: 0.943 | Expected Value: $2.32\n",
      "\n",
      "--- Anthony Edwards ---\n",
      "Averaging 40.0 minutes with 26.0 FGA/game\n",
      "\n",
      "Model predicted mean: 8.51 reboundsTotal (adjusted)\n",
      "Model standard deviation: 2.10\n",
      "\n",
      "95% Prediction Interval for Linear Regression: (7.82, 10.18)\n",
      "\n",
      "Vegas over line: 8.5 at odds 100\n",
      "Vegas implied probability: 50.00%\n",
      "Model probability of winning bet: 50.21%\n",
      "Edge over Vegas: 0.21%\n",
      "Expected Value (EV): $0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### Version #5 with using individual game data not averages\n",
    "#Link to kaggle page : https://www.kaggle.com/datasets/eoinamoore/historical-nba-data-and-player-box-scores?select=PlayerStatistics.csv\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "\n",
    "# Normalization helper\n",
    "def normalize_features(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "# Train/Test Split and Model Training with Random Forest and Linear Regression\n",
    "def train_models_with_comparison(data, features, target):\n",
    "    X = data[features]\n",
    "    y = data[target]\n",
    "\n",
    "    # Fill and scale features\n",
    "    X = X.fillna(X.mean())\n",
    "    X_scaled, scaler = normalize_features(X)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    lr_train_preds = lr_model.predict(X_train)\n",
    "    lr_residuals = y_train - lr_train_preds\n",
    "    lr_model.sigma_ = np.std(lr_residuals)\n",
    "    \n",
    "    # Random Forest\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    lr_mse = mean_squared_error(y_test, lr_model.predict(X_test))\n",
    "    rf_mse = mean_squared_error(y_test, rf_model.predict(X_test))\n",
    "\n",
    "    \n",
    "    print(f\"Random Forest RMSE: {math.sqrt(rf_mse):.4f}\")\n",
    "\n",
    "    return lr_model, rf_model, scaler, X_train, X_test\n",
    "\n",
    "\n",
    "\n",
    "# Prediction Interval for Linear Regression\n",
    "def predict_with_prediction_interval(model, scaler, X_train_scaled, sample_features, alpha=0.05):\n",
    "    sample_features_scaled = scaler.transform(sample_features)\n",
    "    predicted_value = model.predict(sample_features_scaled)[0]\n",
    "    z_score = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "    XTX_inv = np.linalg.pinv(X_train_scaled.T @ X_train_scaled)\n",
    "    x_0 = sample_features_scaled[0].reshape(-1, 1)\n",
    "    variance = model.sigma_**2 + (x_0.T @ XTX_inv @ x_0)[0, 0]\n",
    "\n",
    "    margin_error = z_score * np.sqrt(variance)\n",
    "    lower_bound = predicted_value - margin_error\n",
    "    upper_bound = predicted_value + margin_error\n",
    "\n",
    "    return predicted_value, lower_bound, upper_bound\n",
    "\n",
    "\n",
    "\n",
    "# Simple prediction from Random Forest\n",
    "def predict_rf(rf_model, scaler, sample_features):\n",
    "    sample_scaled = scaler.transform(sample_features)\n",
    "    return rf_model.predict(sample_scaled)[0]\n",
    "\n",
    "\n",
    "\n",
    "def load_and_preprocess_player_data(ppg_file, player_name=None):\n",
    "\n",
    "    ppg_data = pd.read_csv(ppg_file)\n",
    "    #print(\"Columns in loaded DataFrame:\", ppg_data.columns)\n",
    "    \n",
    "\n",
    "    ppg_data['first_last'] = ppg_data['firstName'] + ' ' + ppg_data['lastName']\n",
    "\n",
    "    if player_name:\n",
    "        ppg_data = ppg_data[ppg_data['first_last'] == player_name]\n",
    "        \n",
    "\n",
    "    ppg_data['gameDate'] = pd.to_datetime(ppg_data['gameDate'])\n",
    "    ppg_data = ppg_data.sort_values(by=['first_last', 'gameDate'])\n",
    "\n",
    "    ppg_data['game_month'] = ppg_data['gameDate'].dt.month\n",
    "    ppg_data['game_dayofweek'] = ppg_data['gameDate'].dt.dayofweek\n",
    "    ppg_data['days_since_last_game'] = (\n",
    "        ppg_data.groupby('first_last')['gameDate'].diff().dt.days.fillna(7)\n",
    "    )\n",
    "\n",
    "    ppg_data['rolling_avg_points_3'] = (\n",
    "        ppg_data.groupby('first_last')['points']\n",
    "        .rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    )\n",
    "    ppg_data['rolling_avg_points_5'] = (\n",
    "        ppg_data.groupby('first_last')['points']\n",
    "        .rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    ppg_data['mp_pts'] = ppg_data['numMinutes'] * ppg_data['points']\n",
    "    ppg_data['mp_trb'] = ppg_data['numMinutes'] * ppg_data['reboundsTotal']\n",
    "\n",
    "    ppg_data.fillna(ppg_data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    # Downcast numerics\n",
    "    for col in ppg_data.select_dtypes(include='number').columns:\n",
    "        ppg_data[col] = pd.to_numeric(ppg_data[col], downcast='float')\n",
    "\n",
    "    # Define the features for the model\n",
    "    features = [\n",
    "        'numMinutes', 'blocks', 'steals', 'foulsPersonal', 'turnovers', 'days_since_last_game',\n",
    "        'assists', 'fieldGoalsAttempted', 'fieldGoalsMade', 'threePointersAttempted', 'threePointersMade',\n",
    "        'freeThrowsAttempted', 'freeThrowsMade', 'rolling_avg_points_3', 'rolling_avg_points_5',\n",
    "        'plusMinusPoints', 'reboundsDefensive', 'reboundsOffensive', 'reboundsTotal',\n",
    "        'mp_pts', 'mp_trb',\n",
    "        'game_month', 'game_dayofweek', 'playerteamName', 'opponentteamName', 'home'\n",
    "    ]\n",
    "\n",
    "    return ppg_data, features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_expected_value_from_prediction(\n",
    "    predicted_points, sigma, sportsbook_line, odds, over=True\n",
    "):\n",
    "    # Calculate probability from normal distribution\n",
    "    if over:\n",
    "        prob_win = 1 - norm.cdf(sportsbook_line, loc=predicted_points, scale=sigma)\n",
    "    else:\n",
    "        prob_win = norm.cdf(sportsbook_line, loc=predicted_points, scale=sigma)\n",
    "    \n",
    "    prob_loss = 1 - prob_win\n",
    "\n",
    "    # Convert odds to decimal\n",
    "    if odds > 0:\n",
    "        payout_ratio = odds / 100\n",
    "    else:\n",
    "        payout_ratio = 100 / abs(odds)\n",
    "\n",
    "    # Expected value, assuming $100 bet\n",
    "    ev = (prob_win * payout_ratio * 100) - (prob_loss * 100)\n",
    "    \n",
    "    return ev, prob_win\n",
    "\n",
    "\n",
    "\n",
    "def calculate_betting_edge(blended_mean, std_dev, sportsbook_line, odds, bet_type='over'):\n",
    "    \"\"\"\n",
    "    Calculate expected value and model probability for a given bet.\n",
    "    \"\"\"\n",
    "    # Convert betting odds to implied probability\n",
    "    if odds > 0:\n",
    "        vegas_prob = 100 / (odds + 100)\n",
    "    else:\n",
    "        vegas_prob = -odds / (-odds + 100)\n",
    "\n",
    "    # Calculate model probability\n",
    "    if bet_type.lower() == 'over':\n",
    "        model_prob = 1 - norm.cdf(sportsbook_line, loc=blended_mean, scale=std_dev)\n",
    "    else:  # Under\n",
    "        model_prob = norm.cdf(sportsbook_line, loc=blended_mean, scale=std_dev)\n",
    "\n",
    "    # Calculate expected value (simple)\n",
    "    payout_multiplier = odds / 100 if odds > 0 else 100 / abs(odds)\n",
    "    ev = (model_prob * payout_multiplier) - (1 - model_prob)\n",
    "\n",
    "    # Calculate model edge\n",
    "    edge = model_prob - vegas_prob\n",
    "\n",
    "    return ev, model_prob, vegas_prob, edge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Functions used to calculate the mean without accounting for fluke / blowout games\n",
    "def weighted_mean(df, stat_col='points', weight_col='numMinutes'):\n",
    "    valid = df[(df[weight_col] > 0) & df[stat_col].notna()]\n",
    "    weighted_sum = (valid[stat_col] * valid[weight_col]).sum()\n",
    "    total_weight = valid[weight_col].sum()\n",
    "    return weighted_sum / total_weight if total_weight > 0 else np.nan\n",
    "\n",
    "def ewma_stat(df, stat_col='points', span=5):\n",
    "    sorted_df = df.sort_values('gameDate')\n",
    "    return sorted_df[stat_col].ewm(span=span, adjust=False).mean().iloc[-1]\n",
    "\n",
    "def blended_player_stat(player_data, stat_col='points', span=5, wm_weight=0.6):\n",
    "    wm = weighted_mean(player_data, stat_col=stat_col, weight_col='numMinutes')\n",
    "    ewma = ewma_stat(player_data, stat_col=stat_col, span=span)\n",
    "    \n",
    "    if pd.isna(wm) and pd.isna(ewma):\n",
    "        return np.nan\n",
    "    elif pd.isna(wm):\n",
    "        return ewma\n",
    "    elif pd.isna(ewma):\n",
    "        return wm\n",
    "    else:\n",
    "        return wm_weight * wm + (1 - wm_weight) * ewma\n",
    "    \n",
    "    \n",
    "\n",
    "def adjust_prediction_with_matchup(player_data, opponent_team, player_team, blended_mean, home_game_flag, team_stats, target, print_log):\n",
    "    \"\"\"Adjusts the blended mean based on matchup stats, pace, and home/away effects, and prints each adjustment.\"\"\"\n",
    "\n",
    "    adjustment_log = []  # collect adjustment notes\n",
    "    \n",
    "    \n",
    "     # --- Step 0: Blended Mean ---\n",
    "    blended_mean = blended_player_stat(player_data, stat_col=target)\n",
    "    if pd.isna(blended_mean):\n",
    "        adjustment_log.append(\"Initial blended mean: Failed to calculate (NaN)\")\n",
    "        print(\"Adjustment Breakdown:\")\n",
    "        for adj in adjustment_log:\n",
    "            print(\"  •\", adj)\n",
    "        return np.nan\n",
    "    #adjustment_log.append(f\"Initial blended mean: {blended_mean:.2f} {target}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # --- Get player's last 5 games vs opponent ---\n",
    "    recent_vs_opponent = player_data[player_data['opponentteamName'] == opponent_team].tail(5)\n",
    "    \n",
    "\n",
    "    if not recent_vs_opponent.empty:\n",
    "        opponent_mean = recent_vs_opponent[target].mean()\n",
    "        overall_mean = player_data[target].mean()\n",
    "        opponent_adjustment = (opponent_mean - overall_mean) * 0.5  # weight it moderately\n",
    "        blended_mean += opponent_adjustment\n",
    "        adjustment_log.append(f\"Opponent adjustment: {opponent_adjustment:+.2f} {target}\")\n",
    "    else:\n",
    "        adjustment_log.append(\"Opponent adjustment: None (no recent data)\")\n",
    "\n",
    "    # --- Calculate pace adjustment ---\n",
    "    try:\n",
    "        # Find team stats for both teams\n",
    "        team_row = team_stats[team_stats['teamName'] == player_team].iloc[-1]\n",
    "        \n",
    "        opponent_row = team_stats[team_stats['opponentTeamName'] == opponent_team].iloc[-1]\n",
    "\n",
    "        # Calculate total possessions for each team\n",
    "        team_total_possessions = (\n",
    "            team_row['fieldGoalsAttempted'] +\n",
    "            0.44 * team_row['freeThrowsAttempted'] -\n",
    "            team_row['reboundsOffensive'] +\n",
    "            team_row['turnovers']\n",
    "        )\n",
    "        opponent_total_possessions = (\n",
    "            opponent_row['fieldGoalsAttempted'] +\n",
    "            0.44 * opponent_row['freeThrowsAttempted'] -\n",
    "            opponent_row['reboundsOffensive'] +\n",
    "            opponent_row['turnovers']\n",
    "        )\n",
    "\n",
    "        # Get minutes\n",
    "        team_total_minutes = team_row['numMinutes']\n",
    "        opponent_total_minutes = opponent_row['numMinutes']\n",
    "        \n",
    "        #different weights for different targets for pace adjustment\n",
    "        stat_pace_weights = {\n",
    "            'points': 0.5,\n",
    "            'reboundsTotal': 0.3,\n",
    "            'assists': 0.2,\n",
    "            'steals': 0.1,\n",
    "            'blocks': 0.1,\n",
    "            \n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        if pd.notna(team_total_possessions) and pd.notna(opponent_total_possessions) and pd.notna(team_total_minutes) and pd.notna(opponent_total_minutes) and team_total_minutes > 0 and opponent_total_minutes > 0:\n",
    "            team_pace = (240 / team_total_minutes) * (team_total_possessions)\n",
    "            \n",
    "            opponent_pace = (240 / opponent_total_minutes) * (opponent_total_possessions)\n",
    "\n",
    "            # Average the two paces\n",
    "            game_pace = (team_pace + opponent_pace) / 2\n",
    "            #Average game pace\n",
    "            league_average_pace = 100\n",
    "\n",
    "            #Gets the difference in average pace with that game pace, gets the corresponding weight from \n",
    "            #the feature and adjusts the target prediction \n",
    "            pace_diff_percent = (game_pace - league_average_pace) / league_average_pace\n",
    "            pace_weight = stat_pace_weights.get(target, 0.3)\n",
    "            pace_adjustment = pace_diff_percent * blended_mean * pace_weight\n",
    "            blended_mean += pace_adjustment\n",
    "            \n",
    "            adjustment_log.append(f\"Pace adjustment: {pace_adjustment:+.2f} {target} (Game Pace {game_pace:.1f}, team_pace = {team_pace}, opponent_pace = {opponent_pace}, League Pace {league_average_pace:.1f})\")\n",
    "        else:\n",
    "            adjustment_log.append(f\"Pace adjustment: Skipped because poss = {team_total_possessions}, team_min = {team_total_minutes}, opp_minutes = {opponent_total_minutes}\")\n",
    "    except Exception as e:\n",
    "        adjustment_log.append(f\"Pace adjustment: Failed ({e})\")\n",
    "\n",
    "    # --- Home/Away adjustment ---\n",
    "    if home_game_flag == 1:\n",
    "        home_adjustment = 0.02 * blended_mean  # boost 2% for home\n",
    "        blended_mean += home_adjustment\n",
    "        adjustment_log.append(f\"Home game adjustment: {home_adjustment:+.2f} {target}\")\n",
    "    else:\n",
    "        away_adjustment = -0.02 * blended_mean  # penalty 2% for away\n",
    "        blended_mean += away_adjustment\n",
    "        adjustment_log.append(f\"Away game adjustment: {away_adjustment:+.2f} {target}\")\n",
    "\n",
    "    # --- Print all adjustment steps ---\n",
    "    if print_log:\n",
    "        print(\"\\nAdjustment Breakdown:\")\n",
    "        for adj in adjustment_log:\n",
    "            print(\"  •\", adj)\n",
    "\n",
    "    return blended_mean, adjustment_log\n",
    "\n",
    "\n",
    "# monte carlo based prediction \n",
    "def monte_carlo_adjustment(player_data, opponent_team, player_team, home_game_flag, team_stats, target, sportsbook_line, bet_type='over', n=1000, noise_std=0.05):\n",
    "    \"\"\"\n",
    "    Runs a Monte Carlo simulation by injecting noise into the player's stat distribution and applying the matchup adjustment.\n",
    "    Returns the empirical probability of hitting the bet line (over/under) and expected value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Precompute the base blended mean\n",
    "    base_blended_mean = blended_player_stat(player_data, stat_col=target)\n",
    "\n",
    "    if pd.isna(base_blended_mean):\n",
    "        print(\"Cannot run Monte Carlo: blended mean is NaN\")\n",
    "        return None, None\n",
    "\n",
    "    simulated_predictions = []\n",
    "\n",
    "    # Generate one noisy sample to print the adjustment log\n",
    "    noisy_data = player_data.copy()\n",
    "    noise = np.random.normal(loc=0, scale=noise_std * base_blended_mean, size=len(noisy_data))\n",
    "    noisy_data[target] = noisy_data[target] + noise\n",
    "    noisy_data[target] = noisy_data[target].clip(lower=0)\n",
    "\n",
    "    # Print adjustment log once\n",
    "    first_adjusted, adjustment_log = adjust_prediction_with_matchup(\n",
    "        noisy_data, opponent_team, player_team, base_blended_mean, home_game_flag, team_stats, target, print_log=True\n",
    "    )\n",
    "    if not pd.isna(first_adjusted):\n",
    "        simulated_predictions.append(first_adjusted)\n",
    "\n",
    "    # Run rest of the simulations silently\n",
    "    for _ in range(n - 1):\n",
    "        noisy_data = player_data.copy()\n",
    "        noise = np.random.normal(loc=0, scale=noise_std * base_blended_mean, size=len(noisy_data))\n",
    "        noisy_data[target] = noisy_data[target] + noise\n",
    "        noisy_data[target] = noisy_data[target].clip(lower=0)\n",
    "\n",
    "        adjusted_prediction, _ = adjust_prediction_with_matchup(\n",
    "            noisy_data, opponent_team, player_team, base_blended_mean, home_game_flag, team_stats, target, print_log=False\n",
    "        )\n",
    "\n",
    "        if not pd.isna(adjusted_prediction):\n",
    "            simulated_predictions.append(adjusted_prediction)\n",
    "\n",
    "    # Calculate Monte Carlo-based probability\n",
    "    simulated_predictions = np.array(simulated_predictions)\n",
    "\n",
    "    if bet_type == 'over':\n",
    "        prob = np.mean(simulated_predictions > sportsbook_line)\n",
    "    else:\n",
    "        prob = np.mean(simulated_predictions < sportsbook_line)\n",
    "\n",
    "    # Compute expected value (assuming $100 bet)\n",
    "    payout_ratio = sportsbook_line / 100 if sportsbook_line > 0 else 100 / abs(sportsbook_line)\n",
    "    ev = (prob * payout_ratio * 100) - ((1 - prob) * 100)\n",
    "\n",
    "    print(f\"Monte Carlo {bet_type.upper()} Prob: {prob:.3f} | Expected Value: ${ev:.2f}\")\n",
    "    return prob, ev\n",
    "\n",
    "\n",
    "\n",
    "#Imports the excel file and gets the column of residuals to get the standard error of the estimate\n",
    "def read_xls(residual_file_path, sheet_name=0, **kwargs):\n",
    "    try:\n",
    "        df = pd.read_excel(residual_file_path, sheet_name=sheet_name, engine='xlrd', **kwargs)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{file_path}'\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def main():\n",
    "    # --- File paths and player/team setup ---\n",
    "    ppg_file = '/Users/davislaroque/Desktop/NBA Project/game-by-game-stats/filtered_player_data.csv'\n",
    "    team_stats_file = '/Users/davislaroque/Desktop/NBA Project/game-by-game-stats/filtered_team_stats.csv'\n",
    "    residual_file_path = '/Users/davislaroque/Downloads/NBA Project Results Summary.xls'\n",
    "\n",
    "    \n",
    "    target = 'reboundsTotal'\n",
    "    player_name = \"Anthony Edwards\"\n",
    "    player_team = \"Timberwolves\"\n",
    "    opponent_team = \"Thunder\"\n",
    "    home_game_flag = 0  # 1 for Home, 0 for Away\n",
    "\n",
    "    # --- Load and prepare data ---\n",
    "    player_data, features = load_and_preprocess_player_data(ppg_file, player_name)\n",
    "    team_stats = pd.read_csv(team_stats_file)\n",
    "    team_stats = team_stats[pd.to_datetime(team_stats['gameDate']) >= pd.to_datetime(\"2024-10-22\")]\n",
    "    \n",
    "    if player_data.empty:\n",
    "        print(f\"No data found for player: {player_name}\")\n",
    "        return\n",
    "    \n",
    "    #gets the residuals standard error\n",
    "    df = read_xls(residual_file_path)\n",
    "    residuals = df.Residuals\n",
    "    residuals_std = residuals.std()\n",
    "\n",
    "    #drop team/categorical columns from model training\n",
    "    features = [f for f in features if f not in ['playerteamName', 'opponentteamName']]\n",
    "\n",
    "    \n",
    "    # Remove target column from features to prevent leakage\n",
    "    if target == 'reboundsTotal':\n",
    "        features = [f for f in features if f not in ['reboundsTotal', 'mp_trb']]\n",
    "    elif target == 'points':\n",
    "        features = [f for f in features if f not in ['points', 'mp_pts']]\n",
    "        \n",
    "\n",
    "    # --- Train models ---\n",
    "    lr_model, rf_model, scaler, X_train_scaled, X_test_scaled = train_models_with_comparison(\n",
    "        player_data, features, target\n",
    "    )\n",
    "\n",
    "    # --- Prepare latest sample for prediction ---\n",
    "    player_row = player_data.iloc[[-1]]  # most recent game\n",
    "    numMinutes = player_row[\"numMinutes\"].values[0]\n",
    "    fieldGoalsAttempted = player_row[\"fieldGoalsAttempted\"].values[0]\n",
    "    sample_features = player_row[features].values\n",
    "\n",
    "    alpha = 0.05  # Confidence level for prediction interval\n",
    "\n",
    "    # --- Linear Regression prediction with interval ---\n",
    "    lr_pred, lower, upper = predict_with_prediction_interval(\n",
    "        lr_model, scaler, X_train_scaled, sample_features\n",
    "    )\n",
    "\n",
    "    # --- Random Forest prediction ---\n",
    "    sample_df = pd.DataFrame(sample_features, columns=features)\n",
    "    tree_preds = [tree.predict(scaler.transform(sample_df))[0] for tree in rf_model.estimators_]\n",
    "    rf_pred = np.mean(tree_preds)\n",
    "    rf_std = np.std(tree_preds)\n",
    "\n",
    "    # --- Blended Mean (weighted average of LR and RF) ---\n",
    "    blended_mean = (0.6 * rf_pred) + (0.4 * lr_pred)\n",
    "\n",
    "    # --- Estimate Standard Deviation (blended) ---\n",
    "    historical_std = player_data[target].tail(20).std()\n",
    "    blended_std = (0.6 * historical_std) + (0.4 * rf_std)\n",
    "    blended_std = max(blended_std, 0.1 * rf_pred)\n",
    "\n",
    "    # --- Adjust blended_mean with matchup, pace, home/away ---\n",
    "    adjusted_blended_mean, _ = adjust_prediction_with_matchup(\n",
    "        player_data=player_data,\n",
    "        opponent_team=opponent_team,\n",
    "        player_team=player_team,\n",
    "        blended_mean=blended_mean,\n",
    "        home_game_flag=home_game_flag,\n",
    "        team_stats=team_stats,\n",
    "        target = target,\n",
    "        print_log = False\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # --- Sportsbook Info (manual input) ---\n",
    "    sportsbook_line =8.5\n",
    "    odds = +100\n",
    "    bet_type = 'over'\n",
    "\n",
    "    \n",
    "    \n",
    "    model_prob, ev = monte_carlo_adjustment(\n",
    "    player_data=player_data,\n",
    "    opponent_team=opponent_team,\n",
    "    player_team=player_team,\n",
    "    home_game_flag=home_game_flag,\n",
    "    team_stats=team_stats,\n",
    "    target=target,\n",
    "    sportsbook_line=sportsbook_line,\n",
    "    bet_type=bet_type,\n",
    "    n=1000,\n",
    "    noise_std = residuals_std\n",
    "    )\n",
    "    \n",
    "    # --- Calculate EV, model prob, vegas prob, edge ---\n",
    "    ev, model_prob, vegas_prob, edge = calculate_betting_edge(\n",
    "        adjusted_blended_mean, blended_std, sportsbook_line, odds, bet_type\n",
    "    )\n",
    "\n",
    "    # --- Output ---\n",
    "\n",
    "    print(f\"\\n--- {player_name} ---\")\n",
    "    print(f\"Averaging {numMinutes:.1f} minutes with {fieldGoalsAttempted:.1f} FGA/game\\n\")\n",
    "    print(f\"Model predicted mean: {adjusted_blended_mean:.2f} {target} (adjusted)\")\n",
    "    print(f\"Model standard deviation: {blended_std:.2f}\\n\")\n",
    "    #print(f\"Random Forest raw prediction: {rf_pred:.2f} {target}\\n\")\n",
    "    #print(f\"Linear Regression raw prediction: {lr_pred:.2f} {target}\")\n",
    "    print(f\"95% Prediction Interval for Linear Regression: ({lower:.2f}, {upper:.2f})\\n\")\n",
    "\n",
    "    print(f\"Vegas {bet_type} line: {sportsbook_line} at odds {odds}\")\n",
    "    print(f\"Vegas implied probability: {vegas_prob * 100:.2f}%\")\n",
    "    print(f\"Model probability of winning bet: {model_prob * 100:.2f}%\")\n",
    "    print(f\"Edge over Vegas: {edge * 100:.2f}%\")\n",
    "    print(f\"Expected Value (EV): ${ev:.2f}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c0d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF and LR model summarys\n",
    "\n",
    "\n",
    "#    import statsmodels.api as sm\n",
    "\n",
    "#     X = player_data[features].fillna(player_data[features].mean())\n",
    "#     X = sm.add_constant(X)  # adds intercept\n",
    "#     y = player_data[target]\n",
    "\n",
    "#     model = sm.OLS(y, X).fit()\n",
    "#     print(model.summary())\n",
    "    \n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     feature_importance = rf_model.feature_importances_\n",
    "#     sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.barh([features[i] for i in sorted_idx], feature_importance[sorted_idx])\n",
    "#     plt.xlabel(\"Feature Importance\")\n",
    "#     plt.title(\"Random Forest Feature Importances\")\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
